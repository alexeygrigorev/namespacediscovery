\section{Introduction}

\subsection{Namespaces in Computer Science}

In computer science, a \emph{namespace} refers to a collection of terms
that are managed together because they share functionality or purpose,
typically for providing modularity
and resolving name conflicts \cite{duval2002metadata}.

Namespaces are used in XML (eXtensible Markup Language), which
is a framework for defining markup languages.
XML lets users define a set of tags to represent information in some
specific domain \cite{moller2006introduction}. For example, XHMTL is an XML
language for hypertext markup and MathML is a language for describing mathematical
notation.

However, different XML languages may use the same names for elements and attributes.
For example, consider two XML languages: XHTML for specifying the layout of web
pages, and some XML language for describing furniture. Both these languages have
the \verb|<table>| elements there, in XHTML table is used to present some data in
a tabular form, while the second one uses it to describe a particular piece of
furniture in the database.

The \verb|<table>| elements have very different semantics in these languages
and there should be a way to distinguish between these two elements.
In XML this problem is solved with XML namespaces~\cite{xmlnamespaces}:
the namespaces are used to ensure the uniqueness of attributes and resolve ambiguity.
It is done by binding a short namespace alias with some uniquely defined URI
(Unified Resource Identifier), and then appending the alias to
all attribute names that come from this namespace. In the example above,
we can bind an alias \verb|h| with XHTML's URI \url{http://www.w3.org/TR/xhtml1}
and then use \verb|<h:table>| to refer to XHTML's table. Likewise,
in the furniture database language the element names can be prepended
with a prefix \verb|d|, where \verb|d| is bound to some URI, e.g.
\url{http://www.furniture.de/2015/db}.


% Ralf's comment: ``namespaces" were deeply studied mainly in
% the field of distributed systems/ middleware (like DCE, CORBA, etc.) in the middle
% of the 80s/ 90s ...


Namespaces are also used in programming languages for organizing
variables, procedures and other identifiers into groups and
for resolving name collisions. In programming languages without
namespaces the programmers have to take special care to avoid
naming conflicts. For example, in the PHP programming language
prior to version 5.3 \cite{mcarthur2008php6} there is no notion of namespace, and
the namespaces have to be emulated to ensure that the names
are unique, and long names like
\verb|Zend_Search_Lucene_Analysis_Analyzer|\footnote{\url{http://framework.zend.com/apidoc/1.7/Zend_Search_Lucene/Analysis/Zend_Search_Lucene_Analysis_Analyzer.html}}.
is the result.

Other programming languages have the notion of namespaces built in
from the very first versions. For example, the Java programming
language~\cite{gosling2014java} uses packages to organize identifiers into
namespaces, and packages solve the problem of ambiguity. For example,
in the standard Java API there are two classes with the name \texttt{Date}:
one in the package \texttt{java.util} and another in the package \texttt{java.sql}.
To be able to distinguish between them, the classes are referred by their
\emph{fully qualified name}: an unambiguous name that uniquely specifies the class
by combining the package name with the class name. Thus, to refer to a particular
\texttt{Date} class in Java  \texttt{java.util.Date} or  \texttt{java.sql.Date}
should be used.

It is not always convenient to use the fully qualified name in the code to
refer to some class from another package. Therefore in Java it is possible to
\emph{import} the class by using the import statement which associates
a short name alias with its fully qualified name.
For example, to refer to \texttt{java.sql.Date} it is possible to import
it by using \texttt{import java.sql.Date} and then refer to it by the alias
\texttt{Date} in the class \cite{gosling2014java}.


Although there is no strict requirement to organize the classes into
well defined groups, it is a good software design practice to put
related objects into the same namespace and by doing this achieve
better modularity. There are design principles that tell software engineers
how to best organize the source code: classes in a well designed system
should be grouped in such a way that namespaces
exhibit low \emph{coupling} and high \emph{cohesion}~\cite{larman2005applying}.
Coupling describes the degree of dependence between namespaces, and
low coupling means that the interaction between classes of different
namespaces should be as low as possible. Cohesion, on the other hand,
refers to the dependence within the classes of the same namespace,
and the high cohesion principle says that the related classes
should all be put together in the same namespace.

% TODO What's the significance?


\subsection{Namespaces in Mathematical Notation}

The idea of namespaces can be extended to identifiers in mathematical 
formulae. 

Informally, a mathematical formula is a rule that shows the relationship
between different variables. For example,
$x_{1,2} = \frac{-b \pm \sqrt{b^2 - 4 a c}}{2 a}$ is a formula for solving
a quadratic equation $a x^2 + b x + c = 0$.


To give a more formal definition of formula, we first need to define
a first-order language that contains primitive symbols such as
(1) parentheses, brackets and other boundary symbols,
(2) \emph{constants} ($1$, $2$, $3$, ...) and variables ($x$, $y$, ...),
(3) \emph{functions} ($+$, $\times$, ...) and
(4) \emph{predicates}, e.g. binary relation symbols (``$=$'', ``$<$'', ``$\geqslant$'', ...)
\cite{barwise2000language}.

In this language, \emph{constants} are symbols with pre-defined meaning
from some alphabet and \emph{variables} are symbols that can be assigned
a value from this alphabet.
Any symbol can be a variable, including symbols with subscripts. For example,
$x$, $y$, $\mathbf w$ are variables, but so are $x_1, x_2, \ ...$ or even $w_\text{slope}$.

A \emph{well-formed term} $t$ (or just \emph{term}) in this language is defined as
$$t \equiv c \mid x \mid f(t_1, t_2, \ ... \ , t_n) \ ,$$ which means that the term
$t$ can be a constant, a variable or an $n$-ary function
$f(t_1, t_2, \ ... \ , t_n)$. An  \emph{$n$-ary function} is an
function that takes $n$ terms $t_1, t_2, \ ... \ , t_n$ and produces
a new term $t$. An \emph{$n$-ary predicate} (or an \emph{$n$-ary relation symbol})
is typically a boolean-valued function that can be evaluated to \texttt{True}
or \texttt{False} depending on the values it gets.

Then an \emph{atomic well-formed formula} (or just \emph{formula}) in this language
is a $n$-ary predicate with $n$ terms evaluated to \texttt{True} \cite{barwise2000language}.

For example, $x_{1,2} = \frac{-b \pm \sqrt{b^2 - 4 a c}}{2 a}$ is a formula,
because it represents an equation that always holds true for a quadratic equation
$a x^2 + b x + c = 0$. The equality symbol ``$=$'' is a predicate that shows
the relationship between variables $x_1, x_2$ and variables $a, b, c$.

In logic we can use any symbol for variables without changing the meaning of the formula.
For example, the energy-mass equivalence relation $E = mc^2$ can be written
as $x = y z^2$ and it will still hold true and remain a valid formula.
Nevertheless, there are research communities in mathematics that have developed
a special system of naming these variables, and this naming system is
called \emph{mathematical notation} \cite{wikinotation}. % couldn't find the better source
For each symbol in a formula, the notation assigns it a precise semantic
meaning. Therefore, because of the notation, in Physics it is more common
to write $E = mc^2$ rather than $x = y z^2$, because the notation assigns
unambiguous meaning to the symbols ``$E$'', ``$m$'' and ``$c$'', and the
meaning of these symbols is recognized among physicists.

However, notations may conflict. For example, while it is common to use
symbol ``$E$'' to denote ``Energy'' in Physics, it also is used in Probability and
Statistics to denote ``Expected Value'', or in Linear Algebra to denote
``Elimination Matrix''.
We can compare the conflict of notations with the name collision problem
in namespaces, and try to address this problem by extending the notion of
namespaces to mathematical notation.

Thus, let us define a \emph{notation} $\mathcal N$ as a set of pairs $\{ (i, s) \}$,
where $i$ is a symbol or \emph{identifier} and $s$ is its semantic meaning
or \emph{definition}, such that for any pair $(i, s) \in \mathcal N$ there
does not exist another pair $(i', s') \in \mathcal N$ with $i = i'$.
Two notations $\mathcal N_1$ and $\mathcal N_2$
\emph{conflict}, if there exists a pair $(i_1, s_1) \in \mathcal N_1$ and a pair
$(i_2, s_2) \in \mathcal N_2$ such that $i_1 = i_2$ and $s_1 \ne s_2$.

Then we can define \emph{namespace} as a named notation, i.e. a pair
$(n, \mathcal N)$ where $\mathcal N$ is a notation and $n$ is its \emph{name}:
a string that uniquely identifies the notation. For example,
$(\text{``Physics''}, \mathcal N_\text{physics})$ can refer to the notation
used in Physics.
For convenience, in this work we can use the Java syntax to refer to
specific entries of a namespace. If $(n, \mathcal N)$ is a namespace and $i$
is an identifier such that $(i, s) \in \mathcal N$ for some $s$, then
``$n$.$i$'' is a \emph{fully qualified name} of the identifier $i$ that
relates $i$ to the definition $s$. For example,
given a namespace $\big( \text{``Physics''},$ $\{ (E, \text{``energy''}),$
$(m, \text{``mass''}),$ $(c, \text{``speed of light''}) \} \big)$,
``Physics.$E$'' refers to ``energy'' -- the definition of ``$E$'' in the
namespace ``Physics''.

% TODO extend it to hierarchies ?

Analogously to namespaces in Computer Science, formally a mathematical namespace
can contain any set of identifier-definition pairs that satisfies the definition of
the namespace, but typically namespaces of mathematical notation
exhibit the same properties as well-designed software packages: they
have low coupling and high cohesion, meaning that all definitions
in a namespace
come from the same area of mathematical knowledge and the definitions
from different namespace do not intersect heavily.

However, mathematical notation does not exist in isolation, and it is usually
observed indirectly by its usage in documents.
Therefore we need to introduce a document-centric view on mathematical
namespaces: suppose we have a collection of $n$ documents
$\mathcal D = \{ d_1, d_2, \ ... \ , d_n \}$ and a set of $K$ namespaces
$\big\{(n_1, \mathcal N_1), (n_2, \mathcal N_2), \ ... \ ,$ $(n_K, \mathcal N_K) \big\}$.
A document $d_j$ can use a namespace $(n_k, \mathcal N_k)$ by \emph{importing}
identifiers from it. To import an identifier, the document uses an import statement
where the identifier $i$ is referred by its fully qualified name.
For example, a document ``Energy-mass equivalence'' would import
``Physics.$E$'', ``Physics.$m$'', and ``Physics.$c$'', and then
these identifiers can be used in formulae of this document unambiguously.

Then a namespace exhibits low coupling if it is used only in a small 
subset of documents, and high cohesion if all the documents in this subset 
are related to the same domain. 

But in real-life scientific document there are no import statements
in the document preamble, and they contain only natural language
texts along with some mathematical formulae. Yet we may still assume
that these import exists, but they are implicit, i.e. they are latent
and cannot be observed directly. Additionally, the namespaces themselves are
also not observed.

Typically in mathematical texts, when an identifier is first introduced, 
its definition is given in the natural language description that surrounds 
the formula. This description can be extracted and used to assign the meaning to
the identifiers. Once identifier definitions are extracted, a document
can be represented as a set of identifier-definition pairs,
and these pairs can be used to discover the namespaces.


In this work we study the problem of namespace discovery and the
goal of this work is to \textbf{automatically discover a set of identifier
namespaces given a collection of documents}.

In the next section we discuss how this problem can be addressed.


\subsection{Discovery of Identifier Namespaces}


How we can construct a set of namespaces given a collection of documents?
It is possible to do manually by assigning each identifier/definition pair
to some namespace, but it is expensive and very time consuming. Therefore
in this work we suggest a different approach: use Machine Learning techniques 
for discovering namespaces automatically.

We illustrate our idea by first drawing an analogy between identifier
namespaces and namepsaces in programming languages.
In a well-designed application, we can distinguish between two types of
application packages \cite{evans2004domain}:

\begin{itemize}
  \item \emph{type 1}: domain-specific packages that deal with one particular
    concept or domain area, and
  \item \emph{type 2}: packages that use other packages of
    the first type
\end{itemize}

For example, for an application \verb|org.company.app|
there can be several domain-specific packages: \verb|org.company.app.domain.user|
with classes related to users, \verb|org.company.app.domain.account|
with classes related to user accounts, and a system-related package
\verb|org.company.app.tools.auth| that deals with authentication and
authorization. Then we also have a package \verb|org.company.app.web.manage|,
which belongs to the type 2: it handles web requests
while relying on classes from packages \verb|user| and \verb|account| to
implement the business logic and on \verb|auth| for making sure the
requests are authorized.

We can observe that the type 1 packages are mostly self-contained
and not highly coupled between each other, but type 2 packages mostly
use other packages of type 1: they depend on them.

This idea can be extended on the document-centric view on
identifier namespaces. Each document can be seen as a class that
imports identifiers defined in other documents.
Then the documents can be grouped together based on the identifiers
and the definitions they have, and then among these groups
there are some groups of documents that are of \emph{type 1}
and the rest are of \emph{type 2}. The type 1 document groups
contain information about closely related concepts, and they are
very homogenous (they have high cohesion), and they are also
not highly coupled with other document groups.
By using the import metaphor, we can say that the type 1 document groups
import only from few closely related namespaces.
Other documents are of \emph{type 2} and they do not have
low coupling: they are not very homogenous and they import from several namespaces

With this intuition we can refer to \emph{type 1} document groups
as \emph{namespace defining} groups. These groups can be seen as ``type 1''
packages: they define namespaces that are used by other \emph{type 2}
document groups. Once the namespace defining groups are found,
we can learn the namespace of these document.

Thus we need to find groups of homogenous documents given a
collection, and this is exactly what Cluster Analysis methods do.

In the next section we will argue why we can use traditional
document clustering techniques and what are the characteristics
that texts and identifiers have in common.


\subsection{Namespace Discovery by Cluster Analysis} \label{sec:clusters-namespaces}

We believe that cluster analysis techniques developed for text documents
should also work for cases when documents are represented by
identifers they contain.

First, let us consider the characteristics of text data.
A natural language typically contains many different words.
If $\mathcal V$ is a set of all possible words in a document collection,
then usually $|\mathcal V| \approx 10^5$, but each individual document 
may contain only a small portion of these words \cite{manning2008introduction}. 
Numbers of words across different documents may wary a lot, and the 
word distribution usually follows some power law distribution, 
e.g. Zipf's law \cite{manning2008introduction}.
Power laws are commonplace \cite{newman2005power}, so it is safe to assume
that number of identifiers across documents are also distributed according
to some power law. Intuitively, it is true because there are many identifiers
like $x$ or $n$ that are very frequent and used in all mathematical articles,
while there are some quite specific identifiers like $\ell_\infty$ that do
not occur very often. We verify this assumption in the implementation chapter
(see Definition Extraction, section~\ref{sec:defextraction-impl}).


Additionally, natural languages suffer from lexical problems of variability
and ambiguity, and the two main problems are synonymy and polysemy
\cite{deerwester1990indexing} \cite{gliozzo2009semantic}:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
  \item two words are \emph{synonymous} if they have the same meaning
        (for example, ``word'' and ``term'' are synonyms),
  \item a word is \emph{polysemous} is it can have multiple meanings
        (for example, ``trunk'' can refer to a part of elephant or a part of a car).
\end{itemize}

We can note that identifiers have the same problems. For example,
in Information Theory, the Shannon Entropy is usually denoted by
``$H$'', but sometimes it is also denoted by ``$I$'' or by ``$S$'',
thus these identifiers may be seen as synonyms.
Also, ``$E$'' can stand both for ``Energy'' and ``Expected value'',
so ``$E$'' is polysemous.

These problems have been studied in Information Retrieval and
Natural Language Processing literature.
One possible solution for the polysemy problem is \emph{Word Sense Disambiguation}
\cite{jurafsky2000speech}: either replace a word with its sense
\cite{stokoe2003word} or append the sense to the word. For example,
if the polysemous word is ``bank'' with meaning ``financial institution'',
then we replace it with ``bank\_finance''. The same idea can be used
for identifiers, for example if we have an identifier ``$E$'' which is
defined as ``energy'', then ``$E$'' can be replaced with ``$E$\_energy''.

Thus we see that text representation of documents and identifier representation
of documents have many similarities and therefore we can apply the set of
techniques developed for text representation for clustering documents based
on identifiers.

For document clustering, documents are usually represented using
Vector Space Models \cite{oikonomakou2005review} \cite{aggarwal2012survey}.
Likewise, we can introduce ``Identifier Space Model'' analogously to
Vector Space Models, and then we can apply clustering algorithm 
to documents represented in this space. 


\subsection{Thesis Outline}

As discussed, it is important to disambiguate identifiers in mathematical 
formulae. One way of doing it is extracting definitions of these identifiers 
from the document, and we discuss the methods for doing it in chapter~\ref{sec:definitionextraction-top}.

In chapter~\ref{sec:namespaces-top} we review the vector space model of 
representing documents and cluster analysis methods used for finding 
groups in documents; and we also study how matrix decomposition 
techniques  can be used to extract semantic information from the corpus. 

Finally, we describe how these techniques are implemented and evaluated in 
chapter~\ref{sec:implementation}.

