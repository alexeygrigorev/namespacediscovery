\section{Mathematical Definition Extraction} \label{section:definitionextraction}
Mathematical expressions are hard to understand without the natural language description,
so we want to find identifiers in the mathematical expressions and extract their
definition from the surrounding text

Example:

The precision $P$ is defined as $P = \cfrac{w}{w + y}$ where $w$ is the number of
correctly labeled pairs and $y$ is the number of incorrectly labeled pairs

We want to extract:

($P$, "precision"),
($w$, "the number of correctly labeled pairs"),
($y$, "the number of incorrectly labeled pairs")

Another example: "Let $e$ be the base of natural logarithm"

want to extract ($e$, "the base of natural logarithm")


A phrase that defines a mathematical expression consists of three parts \cite{kristianto2012extracting}:

\begin{itemize}
  \item \emph{definiendum}, a mathematical expression or identifier, is the term to be defined;
  \item \emph{definiens} is the definition itself: it is the word or phrase that defines the definiendum in a definition.
  \item \emph{definitor} is a relator verb that links definiendum and definiens.
\end{itemize}

In this work we are interested only in first two parts: definiendum and definiens.
Thus we define a \emph{relation} as a pair (definiendum, definiens). Since we are
interested in finding definitions only for identifiers, we restrict ourselves only
to (identifier, definition) relations.


% TODO:
An \emph{identifier} is a mathematical ...


\subsection{Formula Representation: MathML}

MathML \cite{mathml} stands for ``Mathematical Markup Language''
It is is a standard for mathematical
expressions defined by W3C that browsers should support to render math
formulas. There are two types of MathML: Presentation MathML, which describes
how mathematical expressions should be displayed, and Content MathML, which
focuses on the meaning of mathematical expressions. In this section, we will discuss
Presentation MathML .


A \emph{token} in MathML is an individual symbol, name or number. Tokens
are grouped together to form MathML expressions.

Tokens can be:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  identifier, variable or function names
\item
  numbers
\item
  operators (including brackets - so called ``fences'')
\item
  text and whitespaces
\end{itemize}

A ``symbol'' is not necessarily one character: it could be a string such
as \texttt{<mi>sin</mi>}
or \texttt{<mn>24</mn>}.
In MathML they are treated as single tokens.


As in mathematics, MathML expressions are constructed recursively from
smaller expressions or single tokens. Complex expressions are created
with so-called ``layout'' constructor elements, while tokens are created
with token elements.

Let us consider an example. A mathematical expression $(a + b)^2$
can be represented in MathML as follows:

\begin{verbatim}
<math xmlns="http://www.w3.org/1998/Math/MathML">
  <msup>
    <mrow>
      <mo>(</mo>
      <mrow>
        <mi>a</mi>
        <mo>+</mo>
        <mi>b</mi>
      <mrow>
      <mo>)</mo>
    </mrow>
    <mn>2</mn>
  </msup>
</math>
\end{verbatim}


It has the tree structure and recursive. If we take another mathematical
expression $\cfrac{3}{(a + b)^2}$. It is a
fraction and we see that its denominator is the same as the previous
expression. This is also true for the MathML representation:

\begin{verbatim}
<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mfrac>
    <mn>3</mn>
    <msup>
      <mrow>
        <mo>(</mo>
        <mrow>
          <mi>a</mi>
          <mo>+</mo>
          <mi>b</mi>
        <mrow>
        <mo>)</mo>
      </mrow>
      <mn>2</mn>
    </msup>
  </mfrac>
</math>
\end{verbatim}

\ \\


Token Elements

\ \\

Token elements are needed for representing tokens: the smallest units of
mathematical notation that convey some meaning.

There are several token elements:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \texttt{mi} identifier
\item
  \texttt{mn} number
\item
  \texttt{mo} operator, fence, or separator
\item
  \texttt{mtext} text
\item
  \texttt{mspace} space
\item
  \texttt{ms} string literal
\end{itemize}

Often tokens are just single characters, like
\texttt{<mi>E</mi>} or
\texttt{<mn>5</mn>}, but
there are cases when tokes are multi-character, e.g.
\texttt{<mi>sin</mi>} or
\texttt{<mi>span</mi>}.

In MathML \texttt{mi} elements represent some symbolic name or text that
should be rendered as identifiers. Identifiers could be variables,
function names, and symbolic constants.

Transitional mathematical notation often involve some special
typographical properties of fonts, e.g. using bold symbols e.g.
$\mathbf x$ to denote vectors or capital script symbols
e.g. $\mathcal G$ to denote groups and sets. To address
this, there is a special attribute ``mathvariant'' that can take values
such as ``bold'', ``script'' and others.

Numerical literals are represented with \texttt{mn} elements. Typically
they are sequences of digits, sometimes with a decimal point,
representing an unsigned integer or real number, e.g.
\texttt{<mn>50</mn>} or
\texttt{<mn>50.00</mn>}.

Finally, operators are represented with \texttt{mo} elements. Operators
are ...


\ \\

Layouts

Layout elements are needed to form complex mathematical expressions from
simple ones. They group elements in some particular way. For example:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \texttt{mrow} groups any number of sub-expressions horizontally
\item
  \texttt{mfrac} form sa fraction from two sub-expressions
\item
  \texttt{msqrt} forms a square root (radical without an index)
\end{itemize}

Some layout elements are used to add subscripts and superscripts:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \texttt{msub} attach a subscript to a base
\item
  \texttt{msup} attach a superscript to a base
\item
  \texttt{msubsup} attach a subscript-superscript pair to a base
\end{itemize}

And special kinds of scripts (TODO: describe in more details)

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  \texttt{munder} attach an underscript to a base
\item
  \texttt{mover} attach an overscript to a base
\item
  \texttt{munderover} attach an underscript-overscript pair to a base
\end{itemize}

For example, $\vec v$ will be rendered as

\begin{verbatim}
<math xmlns='http://www.w3.org/1998/Math/MathML'>
  <mover>
    <mi>v</mi>
    <mo>&rarr;</mo>
  </mover>
</math>
\end{verbatim}


This is how we would represent $\hat{ \mathbf x}$ (a bold x with a hat) in MathML:

\begin{verbatim}
<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow>
    <mover>
      <mrow>
        <mi mathvariant="bold">x</mi>
      </mrow>
      <mo>&#x005E;<!-- ^ --></mo>
    </mover>
  </mrow>
</math>
\end{verbatim}

There are more complex elements such as \texttt{mtable}.

MathML presentation elements only suggest specific ways of rendering

Math Entities

Certain characters are used to name identifiers or operators that in
traditional notation render the same as other symbols or usually
rendered invisibly.

entities \texttt{\&InvisibleTimes;} \texttt{\&rarr;}

The complete list of MathML entities is described in [Entities].






\subsection{Automatic Definition Extraction}
We have an identifier and want to find what it stands for.

The definitions of mathematical expressions and identifiers can be found from
the natural text description around the expression.

Assumption: the definitions of mathematical expressions are always noun phrases

In general, a noun phrase can be

\begin{itemize}
  \item a simple noun
  \item a compound noun (e.g. adjective + noun)
  \item a compound noun with a clause, prepositional phrase, etc
\end{itemize}



\subsection{Preprocessing}

The typical (see e.g. \cite{kristianto2012extracting, pagael2014mlp} (more?)) pipeline is the following:

\begin{itemize}
  \item Read corpus of documents in some markup language, e.g. Mediawiki or Latex
  \item Translate all formulas in the documents into MathML
  \item Process MathML formulas
  \item Replace formulas with some placeholder
  \item Annotate text ([[Math-Aware POS Tagging]])
  \item Find relations in the text
\end{itemize}


For example:

%TODO:

% http://habrastorage.org/files/025/1f5/4fa/0251f54fa7a248faa6718839ee060b53.png
% MLP flow


\subsection{Math-aware POS tagging}

NLP is a tool for text processing, but it's also applicable to scientific documents with math expressions. So we can adjust traditional NLP methods to dealing with formulas.


Penn Treebank POS Scheme \cite{santorini1990part}  doesn't have special classes for mathematics.
What we can do is to add other math-related classes:

ID for identifiers (e.g. "... where $E$ stands for energy", $E$ should be tagged as ID)

\verb|MATH| for formulas (e.g. "$E = mc^2$ is the mass-energy equivalence formula", "$E = mc^2$ should be tagged as \verb|MATH|)

Mathematical expressions are usually contained within special tags, e.g. inside
tag \verb|<math>...</math>| for wikipedia, or inside \verb|$...$| for
latex documents.

We find all such mathematical expressions and replace each with a unique single token \verb|MATH_mathID|

the \verb|mathID| could be a randomly generated string or result of some hash function
applied to the content of formula. The latter approach is preferred when we want
to have consistent strings across several runs.

Then we apply traditional [[POS Tagging]] (e.g. via Stanford
CoreNLP \cite{manning2014stanford})
techniques to the textual data. They typically will annotate such \verb|MATH_mathID|
tokens as nouns

after that we may want to re-annotate all math tokens: if it contains only
one identifier, we label it as \verb|ID|, if several - as \verb|MATH|. But in some cases
we want to keep original annotation

after that we can bring the mathematical content back to the document



\subsection{Extraction Methods}
\subsubsection{Nearest Noun Method}
Definition is a combination of adjectives and nouns (also sometimes determinants) in the text before the identifier

\cite{grigore2009towards}
\cite{yokoi2011contextual}


This way it only can be compound nouns without additional phrases.


E.g:

\begin{itemize}
  \item "In other words, the bijection $\sigma$ normalizes $G$ in ..."
  \item It will extract relations ($\sigma$, "bijection")
\end{itemize}



\subsubsection{Pattern Matching Methods}

Use patterns to extract definitions

For example,

\begin{itemize}
  \item DESC IDENTIFIER (this is actually the same as nearest noun method)
  \item let|set IDENTIFIER denote|denotes|be DESC
  \item DESC is|are denoted|defined|given as|by IDENTIFIER
  \item IDENTIFIER denotes|dentore|stand|stands as|by IDENTIFIER
  \item IDENTIFIER is|are DESC
  \item DESC is|are IDENTIFIER
  \item and others
\end{itemize}


Patterns taken from
\cite{trzeciak1995writing} (\textbf{TODO}: mention who exactly did that)
and sentence patterns from Graphs and Combinatorics papers from Springer

Used in \cite{quoc2010mining}

Others (\cite{kristianto2012extracting}, \cite{kristianto2014extracting}, \cite{pagael2014mlp})
usually use this method as the baseline for comparison.


\subsubsection{Machine Learning Based Methods}
Formulates definition extraction as a binary classification problem

\begin{itemize}
  \item find candidate pairs (identifier, candidate definition)
  \item candidates are nouns and noun phrases from the same sentence as the expression
\end{itemize}


Features:
\begin{itemize}
  \item sentence patterns (true if one of the patterns can capture this relation - could be separate feature for each pattern)
  \item if there's a colon/comma between candidate and identifier
  \item if there's another math expression between
  \item if candidate is inside parentheses and identifier is outside
  \item word-distance between candidate and identifier
  \item position of candidate relative to identifier
  \item text and POS tag of one/two/three preceding and following tokens around the candidate
  \item unigram/bigram/trigram of previous features
  \item text of first verb between candidate and identifier
  \item others
\end{itemize}

Classifiers:
[[SVM]] (linear kernel) (\cite{kristianto2014extracting}, \cite{yokoi2011contextual})

[[Conditional Random Fields]] (\cite{kristianto2014extracting})


\subsubsection{Probabilistic Approaches}
Mathematical Language Processing (MLP) Approach \cite{pagael2014mlp}: Statistical definition discovery: rank candidate definitions by probability and design an
information extraction system that shots the most relevant (i.e. probable)
definition to the reader to facilitate reading scientific texts with mathematics.


The main idea: the definitions occur very closely to identifiers in sentences.


extract identifiers from MathML


Two assumptions

\begin{itemize}
  \item identifier and its definition occur in the same sentence, so the candidates are
  taken only from the same sentences (as in the ML approach)
  \item definitions are likely occur earlier in the document when authors introduce
  the meaning of an identifier, in subsequent uses the definition is typically not repeated
\end{itemize}

These assumptions are used in the ranking formula

each candidate is ranked with the following weighed sum:

$$R(n, \Delta, t, d) = \cfrac{\alpha \, R_{\sigma_d}(\Delta) + \beta \, R_{\sigma_s}(n) + \gamma \, \text{tf}(t, s)}{\alpha + \beta + \gamma}$$

where

$t$ is the candidate term,
$s$ set of sentences in the document,
$\Delta$ is the distance (the amount of word tokens) between identifier and the candidate term $t$,
$n$ n is the number of sentences between the formula where the identifier is used and
the place where the definition candidate is found.

The distances modeled with Gaussian (instead of taking the raw ones)

$$R_{\sigma}(\Delta) = \exp \left( -\cfrac{1}{2} \cdot {\Delta^2 - 1}{\sigma_2} \right)$$

assume that the probability to find a relation at $\Delta = 1$ is maximal

Finding Parameters $\sigma_d$ and $\sigma_s$

$\sigma_d$ - the standard deviation of Gaussian that models the distance to definition candidate
manual evaluation showed that $R_{\sigma_d}(1) \approx R_{\sigma_d}(5)$,
i.e. it's two times more likely to find the real definition at distance $\Delta=1$
than at distance $\Delta=5$.
thus $\sigma_d = \sqrt{\cfrac{12}{\ln 2}}$


% TODO: check that
$\sigma_s$ - the standard deviation of the Gaussian that models the distance
from the beginning of document
%
$\sigma_s = 2 \sqrt{\cfrac{1}{\ln 2}}$


weights $\alpha, \beta, \gamma$:
$\alpha = \beta = 1$ and
$\gamma = 0.1$ because some valid definitions may occur more often than other
valid definitions, e.g. "length" vs "Hamiltonian"


\subsubsection{Other Ideas}
Translation of mathematical formulas to English using machine-translation techniques
\cite{nghiem2012towards}

Expand or delete?


\subsection{Performance Measures}

TODO: Write more about this

\begin{itemize}
  \item Precision: no of math expresssion with correctly extracted definitions / no of extracted definitions
  \item Recall: no of math expresssion with correctly extracted definitions / no of expressions with definitions
  \item $F_1 = 2PR / (P + R)$: harmonic mean between P and R
\end{itemize}


