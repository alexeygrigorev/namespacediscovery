\section{Conclusions}

\subsection{Result analysis}

Hierarcical methods are too slow, and SLINK is not good.
Bisecting $K$-Means is good for explaining steps but not very practical

MiniBatch K means is preferred to usual KMeans:
fast but same results

NMF takes a lot of time to decompose a matrix with large
$k$

 $k=100$ 30 min, but with results inferior to SVD
 $k=250$ 2 hours, with results comparable to SVD

The complexity of NMF is $O(kn)$


The best definition embedding technique is soft association
The best clsutering algorithm is $K$-Means with $K=10000$
on the semantic space produced by rank-reduced SVD with $k = 200$


\subsection{Experiment Conclusions}

The results are super.



\subsection{Future Work}

In this work we assume that document can import only from one namespace,
but in reality is should be able to import from several namespaces. 
We can allow that by dividing the document in parts (for example, by paragraphs) 
and then treating each part as an independent document. 

Now to determine to which namespace a cluster belong, we use the category 
information. In case when the analysis is applied to the parts of documents, 
each part needs to be assigned to one or more category. 

In this work we only use identifiers, extracted definitions and categories. 
It is possible to take advantage of additional information from Wikipedia 
articles. For example, extract some keywords from the articles 
and use them to get a better cluster assignment. 

The Wikipedia data set can be seen as a graph, where two articles have 
an edge if there is an interwiki link between them. Pages that describe 
certain namespaces may be quite interconnected, and using this idea 
it is possible to apply link-based clustering methods (such as ones 
described in \cite{botafogo1991identifying} and \cite{johnson1996adaptive}) to 
find namespace candidates. There are also hybrid approaches that
can use both textual representation and links \cite{oikonomakou2005review}.

In Latent Semantic Analysis other dimensionality reduction techniques 
can be used, for example, Local Non-Negative Matrix Factorization \cite{li2001learning}. 
There are also randomized Non-Negative Matrix Factorization that use 
random projections \cite{wang2010efficient} \cite{damle2014random} 
that potentially can give a speed up while not significantly losing 
in performance. Another dimensionality reduction technique useful for 
discovering semantics is Dynamic Auto-Encoders \cite{mirowski2010dynamic}.

Finally topic modeling techniques such as Latent Dirichlet Allocation 
\cite{blei2003latent} can be quite useful for modeling namespaces. 
It can naturally model the fact that a document can have several namespaces. 
Also can use Fuzzy Clustering techniques \cite{baraldi1999survey}


We can try different clustering techniques such as Spectral Clustering \cite{ng2002spectral}
or Micro-Clustering \cite{uno2015micro}

other ways to embed identifiers like word2vec \cite{mikolov2013efficient}
or GloVe \cite{pennington2014glove}


The biggest question is how to extend this method to situations when 
no additional information about document category is known. To solve 
it, we need to replace the notion of purity with some other objective 
for discovering namespace-defining clusters. 

We depend on existing hierarchies, and they are not always complete and 
there are mismatches. And when this technique is applied to some
other language, a different hierarchy is needed for this language. When 
we applied it to Russian, we needed to find a different hierarchy.
There should be a way of building these hierarchies
automatically, without the need of external dataset


Also, a metric for evaluating the quality of a namespace is needed. 
Now we assume that pure clusters are namespace-defining clusters. But the namespace
candidates should adhere to the namespace definition as much as possible. 


It can be interesting to apply these techniques to a larger dataset, for example, arXiv.




