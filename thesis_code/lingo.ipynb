{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A$ is tf-idf weighed term-document matrix \n",
    "\n",
    "Terms:\n",
    "\n",
    "- $t_1$: Information\n",
    "- $t_2$: Singular\n",
    "- $t_3$: Value\n",
    "- $t_4$: Computation\n",
    "- $t_5$: Retrieval\n",
    "\n",
    "Documents:\n",
    "\n",
    "- $d_1$: Large Scale **Singular Value Computations**\n",
    "- $d_2$: Software for the Sparse **Singular Value** Decomposition\n",
    "- $d_3$: Introduction to Moderm **Information Retrieval**\n",
    "- $d_4$: Linear Algebra for Intelligent **Information Retrieval**\n",
    "- $d_5$: Matrix **Computations**\n",
    "- $d_6$: **Singular Value** Analysis of Cryptograms\n",
    "- $d_7$: Automatic **Information** Organization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.matrix([[0.00, 0.00, 0.56, 0.56, 0.00, 0.00, 1.00],\n",
    "               [0.49, 0.71, 0.00, 0.00, 0.00, 0.71, 0.00],\n",
    "               [0.49, 0.71, 0.00, 0.00, 0.00, 0.71, 0.00],\n",
    "               [0.72, 0.00, 0.00, 0.00, 1.00, 0.00, 0.00],\n",
    "               [0.00, 0.00, 0.83, 0.83, 0.00, 0.00, 0.00]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.71  2.44  1.31  0.56  0.  ]\n"
     ]
    }
   ],
   "source": [
    "S, U = np.linalg.eigh(A * A.T)\n",
    "\n",
    "order = S.argsort()[::-1]\n",
    "S = S[order]\n",
    "print np.round(S, decimals=2)\n",
    "\n",
    "U = U[:, order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   -0.75  0.   -0.66  0.  ]\n",
      " [-0.65  0.   -0.27  0.   -0.71]\n",
      " [-0.65  0.   -0.27  0.    0.71]\n",
      " [-0.39  0.    0.92  0.    0.  ]\n",
      " [ 0.   -0.66  0.    0.75  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print np.round(U, decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two columns are negative, but we want them be positive. from the orthogonality point of view there's no difference if we change the direction $180^\\text{o}$, so let's do this for first two eigenvectors (and double check that it remains orthonormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.75  0.   -0.66  0.  ]\n",
      " [ 0.65  0.   -0.27  0.   -0.71]\n",
      " [ 0.65  0.   -0.27  0.    0.71]\n",
      " [ 0.39  0.    0.92  0.    0.  ]\n",
      " [ 0.    0.66  0.    0.75  0.  ]]\n",
      "[[ 1.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "U[:, 0:2]  = - U[:, 0:2] \n",
    "print np.round(U, decimals=2)\n",
    "print np.round(U.T.dot(U), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sr = S[S > 1e-6]\n",
    "r = len(Sr)\n",
    "Ur = U[:, 0:r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vr = A.T.dot(Ur).dot(np.diag(1 / Sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.56,  0.56,  0.  ,  0.  ,  1.  ],\n",
       "       [ 0.49,  0.71,  0.  ,  0.  ,  0.  ,  0.71,  0.  ],\n",
       "       [ 0.49,  0.71,  0.  ,  0.  ,  0.  ,  0.71,  0.  ],\n",
       "       [ 0.72,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.83,  0.83,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Ur.dot(np.diag(Sr)).dot(Vr.T), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.where(S.cumsum() / S.sum() > 0.9)[0][0]\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Uk = U[:, 0:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we have the following phrases:\n",
    "\n",
    "- $p_1$ Singular Value \n",
    "- $p_2$ Information Retrieval\n",
    "\n",
    "We treat these phrases as pseudo-documents. \n",
    "\n",
    "\n",
    "I.e. since we have terms:\n",
    "\n",
    "- $t_1$: Information\n",
    "- $t_2$: Singular\n",
    "- $t_3$: Value\n",
    "- $t_4$: Computation\n",
    "- $t_5$: Retrieval\n",
    "\n",
    "We create term-phrase martix $P$, apply tf-idf weights and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = np.matrix([[0.00, 0.56],\n",
    "               [0.71, 0.00],\n",
    "               [0.71, 0.00],\n",
    "               [0.00, 0.00],\n",
    "               [0.00, 0.83]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, apart from phrases, we use the original terms as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.56  1.    0.    0.    0.    0.  ]\n",
      " [ 0.71  0.    0.    1.    0.    0.    0.  ]\n",
      " [ 0.71  0.    0.    0.    1.    0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    1.    0.  ]\n",
      " [ 0.    0.83  0.    0.    0.    0.    1.  ]]\n"
     ]
    }
   ],
   "source": [
    "P = np.hstack([P, np.eye(5)])\n",
    "print P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find descriptions of the clusters (i.e. columns of $U$), calculate $M = U_k^T P$\n",
    "\n",
    "Rows of $M$ represent clusters, columns - their descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.93  0.    0.    0.65  0.65  0.39  0.  ]\n",
      " [ 0.    0.97  0.75  0.    0.    0.    0.66]]\n"
     ]
    }
   ],
   "source": [
    "M = Uk.T * P\n",
    "print np.round(M, decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row need to select the column with the highest value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = np.array(M.argmax(axis=1)).flatten()\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So column 0 and 1 of $P$ give the descriptions: \"Singular Value\" (score 0.93) and \"Information Retrieval\" (score 0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix $Q$ contains columns of $P$ that correspond to selected labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.  ,  0.56],\n",
       "        [ 0.71,  0.  ],\n",
       "        [ 0.71,  0.  ],\n",
       "        [ 0.  ,  0.  ],\n",
       "        [ 0.  ,  0.83]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = P[:, desc]\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the cluster assignment matrix $C$ is $C = Q^T A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.6958,  1.0082,  0.    ,  0.    ,  0.    ,  1.0082,  0.    ],\n",
       "        [ 0.    ,  0.    ,  1.0025,  1.0025,  0.    ,  0.    ,  0.56  ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = Q.T * A\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In $C$ for each column we select row with largest score for the cluster assignment. If the score is low (below some threshold), then we don't assing anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],\n",
       "        [ 0.6958,  1.0082,  0.    ,  0.    ,  0.    ,  1.0082,  0.    ],\n",
       "        [ 0.    ,  0.    ,  1.0025,  1.0025,  0.    ,  0.    ,  0.    ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0.6\n",
    "C = np.vstack([np.zeros(7), C])\n",
    "C[C < t] = 0\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assignemnt = np.array(C.argmax(axis=0)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documetns assingned to default cluster are with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0: [4 6]\n",
      "cluster 1: [0 1 5]\n",
      "cluster 2: [2 3]\n"
     ]
    }
   ],
   "source": [
    "for i in np.unique(assignemnt):\n",
    "    print \"cluster %d:\" % i, np.where(assignemnt == i)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset='all', categories=None, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2, max_features=10000, stop_words='english')\n",
    "# result of vectorizer is normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = vectorizer.fit_transform(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print (tfidf[i] * tfidf[i].T).sum(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer(copy=False)\n",
    "# but result of svd is not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = len(np.unique(dataset.target))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, S, Vt = randomized_svd(tfidf.T, n_components=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000L, 20L) (20L,) (20L, 18846L)\n"
     ]
    }
   ],
   "source": [
    "print U.shape, S.shape, Vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(U.T.dot(U), np.eye(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U_neg = U.sum(axis=0) < 0\n",
    "U[:, U_neg] = -U[:, U_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(U.T.dot(U), np.eye(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terms contributing to topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic #0\n",
      "like: 28.83, posting: 25.04, people: 13.01, organization: 12.91, lines: 12.28, subject: 12.27, writes: 12.16, article: 10.93, com: 10.72, edu: 10.59,\n",
      "\n",
      "topic #1\n",
      "mac: 24.59, scsi: -18.04, 00: -16.30, file: 15.18, state: -11.60, disk: 10.40, people: -9.55, drive: -9.42, windows: -9.41, god: -9.13,\n",
      "\n",
      "topic #2\n",
      "uiuc: 42.63, stanford: -30.29, stratus: 22.24, hp: -17.09, key: 11.01, clipper: 10.19, university: 9.54, netcom: 8.87, edu: -8.75, com: -8.60,\n",
      "\n",
      "topic #3\n",
      "key: -18.54, com: -17.89, access: 16.83, gov: -16.59, uk: 16.43, car: 15.09, cwru: -13.87, god: -13.47, cleveland: -13.06, nasa: 12.47,\n",
      "\n",
      "topic #4\n",
      "gov: -20.32, apple: 17.99, hp: 15.77, uk: 15.42, space: 14.34, dos: 14.15, ac: 13.27, windows: -12.63, nasa: -12.49, edu: 12.45,\n",
      "\n",
      "topic #5\n",
      "vs: 21.01, hockey: 15.65, sgi: -13.38, com: 12.11, apple: -10.94, au: -10.65, team: -9.87, sandvik: -9.47, ca: 9.12, game: 8.96,\n",
      "\n",
      "topic #6\n",
      "msg: 17.53, key: 15.05, drive: -14.27, god: -13.92, digex: -13.25, cc: -12.19, access: 12.18, uk: 11.67, ca: -10.78, scsi: 10.36,\n",
      "\n",
      "topic #7\n",
      "window: -15.02, mit: 14.83, berkeley: -13.54, gatech: -13.37, access: -11.74, andrew: -10.99, drive: 10.91, digex: -9.97, file: 9.58, scsi: 9.54,\n",
      "\n",
      "topic #8\n",
      "cso: 22.65, nec: -16.54, edu: -16.04, virginia: 14.61, cs: -13.49, uiuc: 12.14, ac: 11.57, gov: -11.40, nasa: -10.48, uk: -9.92,\n",
      "\n",
      "topic #9\n",
      "modem: -14.93, israeli: -13.09, andrew: -12.97, columbia: 12.40, israel: -12.24, sale: 11.01, gun: 9.69, edu: -9.41, ibm: 9.36, god: -8.88,\n",
      "\n",
      "topic #10\n",
      "sale: -18.57, space: 15.14, freenet: -15.02, game: -14.38, 00: 12.85, scsi: -11.29, gun: 10.83, ca: -10.24, drive: -9.24, car: -9.20,\n",
      "\n",
      "topic #11\n",
      "window: -16.44, henry: -15.92, ac: 14.26, mark: -13.06, ohio: -12.55, ___: 12.08, uk: -10.77, windows: -10.53, sun: 10.11, __: 9.98,\n",
      "\n",
      "topic #12\n",
      "file: 17.14, apple: -14.81, uiuc: 12.81, sale: 8.78, 00: -8.50, mark: 8.45, henry: 8.37, au: 8.15, washington: -8.12, hp: 7.66,\n",
      "\n",
      "topic #13\n",
      "computer: -10.58, space: -10.54, ohio: -10.46, car: 10.15, ibm: 9.59, washington: 9.58, hp: 9.44, sun: -9.31, stratus: -9.27, cs: -9.03,\n",
      "\n",
      "topic #14\n",
      "israel: 16.51, newsreader: 13.77, state: 11.71, georgia: -10.66, tin: 9.39, version: 9.24, ohio: -9.21, washington: -8.97, hp: 8.95, wpi: -8.92,\n",
      "\n",
      "topic #15\n",
      "bus: -12.37, sandvik: 11.67, window: 11.15, file: 10.30, stratus: -9.82, henry: -9.57, virginia: 9.32, mit: 9.27, duke: -8.82, toronto: 8.51,\n",
      "\n",
      "topic #16\n",
      "cc: 13.67, ti: 11.48, michael: 11.42, keith: -11.34, ohio: 10.39, 00: -9.88, mit: -9.04, columbia: 8.98, jesus: 8.76, mouse: 8.68,\n",
      "\n",
      "topic #17\n",
      "read: 10.80, andrew: 10.65, uk: -10.51, __: -10.14, sun: -9.94, hp: 9.93, space: 9.89, ca: 9.20, cmu: 9.03, ___: -8.38,\n",
      "\n",
      "topic #18\n",
      "world: 12.31, ibm: -10.72, computer: 10.72, banks: 10.26, gordon: -9.94, geb: -9.42, god: -9.33, gov: 9.04, pitt: -9.01, nasa: -8.71,\n",
      "\n",
      "topic #19\n",
      "princeton: -11.93, columbia: -10.39, purdue: -10.24, washington: -9.82, ca: 9.35, netcom: 9.23, car: 9.07, stratus: 8.83, hp: -8.48, mit: -8.45,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "# U here is term-term matrix because we did svd on tfidf.T - i.e. on term-doc matrix, not doc-term\n",
    "\n",
    "for topic_id in xrange(k):\n",
    "    print 'topic #%d' % topic_id\n",
    "    topic = U[:, topic_id]\n",
    "    indices = np.abs(topic).argsort()[::-1][:10]\n",
    "    contribution = topic[indices] * 100\n",
    "    for idx, contrib in zip(np.nditer(indices), np.nditer(contribution)):\n",
    "        print '%s: %0.2f,' % (terms[idx], contrib),\n",
    "    print\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "components = 200\n",
    "lsa = TruncatedSVD(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = lsa.fit_transform(tfidf)\n",
    "X = normalizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "km = MiniBatchKMeans(n_clusters=k, init='k-means++', n_init=1,\n",
    "                     init_size=1000, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=1000, compute_labels=True, init='k-means++',\n",
       "        init_size=1000, max_iter=100, max_no_improvement=10, n_clusters=20,\n",
       "        n_init=1, random_state=None, reassignment_ratio=0.01, tol=0.0,\n",
       "        verbose=0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogeneity: 0.368\n",
      "Completeness: 0.399\n",
      "V-measure: 0.383\n",
      "Adjusted Rand-Index: 0.194\n",
      "Silhouette Coefficient: 0.042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = dataset.target\n",
    "cluster_labels = km.labels_\n",
    "\n",
    "print \"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, cluster_labels)\n",
    "print \"Completeness: %0.3f\" % metrics.completeness_score(labels, cluster_labels)\n",
    "print \"V-measure: %0.3f\" % metrics.v_measure_score(labels, cluster_labels)\n",
    "print \"Adjusted Rand-Index: %.3f\" % metrics.adjusted_rand_score(labels, cluster_labels)\n",
    "print \"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(X, cluster_labels, sample_size=1000)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order_centroids = km.cluster_centers_\n",
    "order_centroids = lsa.inverse_transform(order_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:  space  shuttle  alaska  edu  nasa  moon  launch  orbit  henry  sci\n",
      "Cluster 1:  edu  game  team  games  year  ca  university  players  hockey  baseball\n",
      "Cluster 2:  sale  00  edu  10  offer  new  distribution  subject  lines  shipping\n",
      "Cluster 3:  israel  israeli  jews  arab  jewish  arabs  edu  jake  peace  israelis\n",
      "Cluster 4:  cmu  andrew  org  com  stratus  edu  mellon  carnegie  pittsburgh  pa\n",
      "Cluster 5:  god  jesus  christian  bible  church  christ  christians  people  edu  believe\n",
      "Cluster 6:  drive  scsi  card  edu  mac  disk  ide  bus  pc  apple\n",
      "Cluster 7:  com  ca  hp  subject  edu  lines  organization  writes  article  like\n",
      "Cluster 8:  car  cars  com  edu  engine  ford  new  dealer  just  oil\n",
      "Cluster 9:  sun  monitor  com  video  edu  vga  east  card  monitors  microsystems\n",
      "Cluster 10:  nasa  gov  jpl  larc  gsfc  jsc  center  fnal  article  writes\n",
      "Cluster 11:  windows  dos  file  edu  ms  files  program  os  com  use\n",
      "Cluster 12:  netcom  com  edu  cramer  fbi  sandvik  408  writes  article  people\n",
      "Cluster 13:  armenian  turkish  armenians  armenia  serdar  argic  turks  turkey  genocide  soviet\n",
      "Cluster 14:  uiuc  cso  edu  illinois  urbana  uxa  university  writes  news  cobb\n",
      "Cluster 15:  edu  cs  university  posting  host  nntp  state  subject  organization  lines\n",
      "Cluster 16:  uk  ac  window  mit  server  lines  subject  university  com  edu\n",
      "Cluster 17:  caltech  edu  keith  gatech  technology  institute  prism  morality  sgi  livesey\n",
      "Cluster 18:  key  clipper  chip  encryption  com  keys  escrow  government  algorithm  des\n",
      "Cluster 19:  people  edu  gun  com  government  don  like  think  just  access\n"
     ]
    }
   ],
   "source": [
    "print \"Top terms per cluster:\"\n",
    "\n",
    "order_centroids = order_centroids.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(k):\n",
    "    print \"Cluster %d:\" % i,\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print ' %s' % terms[ind],\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
