{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.sparse\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer(copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29762, 10735)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "doc_categories = defaultdict(set)\n",
    "category_docs = defaultdict(set)\n",
    "\n",
    "category_blacklist = {u'Articles containing proofs', \n",
    "                      u'Articles created via the Article Wizard', \n",
    "                      u'Articles with example pseudocode'}\n",
    "\n",
    "for line in file('C:/tmp/mlp/category_info.txt'):\n",
    "    title, cat = line.strip().split('\\t')\n",
    "    title = title.decode('utf-8')\n",
    "    cat = cat.decode('utf-8')\n",
    "    \n",
    "    if cat in category_blacklist:\n",
    "        continue\n",
    "    \n",
    "    doc_categories[title].add(cat) \n",
    "    category_docs[cat].add(title)\n",
    "\n",
    "print len(doc_categories), len(category_docs)\n",
    "\n",
    "small_cats = set()\n",
    "\n",
    "for cat, docs in category_docs.items():\n",
    "    if len(docs) == 1:\n",
    "        small_cats.add(cat)\n",
    "\n",
    "print len(small_cats)\n",
    "\n",
    "for cat in small_cats:\n",
    "    for doc in category_docs[cat]:\n",
    "        doc_categories[doc].remove(cat)\n",
    "    del category_docs[cat]\n",
    "\n",
    "del small_cats\n",
    "\n",
    "for doc in doc_categories.keys():\n",
    "    if len(doc_categories[doc]) == 0:\n",
    "        doc_categories[doc].add(u'OTHER')\n",
    "    category_docs[u'OTHER'].add(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def id_counter(id_list):\n",
    "    cnt = Counter()\n",
    "    for el in id_list:\n",
    "        cnt[el[u'element']] = el[u'count']\n",
    "    return cnt\n",
    "\n",
    "def_black_list = { 'unit', 'units', 'value', 'values', 'axis', 'axes', 'factor', 'factors', 'line', 'lines',\n",
    "                 'point', 'points', 'number', 'numbers', 'variable', 'variables', 'respect', 'case', 'cases',\n",
    "                 'vector', 'vectors', 'element', 'elements', 'example', \n",
    "                 'integer', 'integers', 'term', 'terms', 'parameter', 'parameters', 'coefficient', 'coefficients',\n",
    "                 'formula', 'times', 'product', 'matrices', 'expression', 'complex', 'real', 'zeros', 'bits',\n",
    "                 'sign',\n",
    "                 'if and only if',\n",
    "                 'alpha', 'beta', 'gamma', 'delta', 'epsilon', 'zeta', 'eta', 'theta', 'iota', 'kappa', 'lambda', \n",
    "                 'mu', 'nu', 'xi', 'omicron', 'pi', 'rho', 'sigma', 'tau', 'upsilon', 'phi', 'chi', 'psi', 'omega'}\n",
    "\n",
    "def valid_def(definition):\n",
    "    if len(definition) <= 3:\n",
    "        return False\n",
    "\n",
    "    return definition.lower() not in def_black_list\n",
    "\n",
    "def rel_to_dict(rels):\n",
    "    res = defaultdict(list)\n",
    "    for r in rels:\n",
    "        if not valid_def(r['definition']):\n",
    "            continue\n",
    "        res[r['identifier']].append((r['definition'], r['score']))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root = 'C:/tmp/mlp/mlp-output/'\n",
    "\n",
    "docs = []\n",
    "titles = []\n",
    "ids = []\n",
    "rels = []\n",
    "\n",
    "empty = 0\n",
    "small = 0\n",
    "\n",
    "for f in os.listdir(root): \n",
    "    for line in file(root + f):\n",
    "        doc = json.loads(line)\n",
    "\n",
    "        title = doc['title']        \n",
    "        if title not in doc_categories:\n",
    "            continue\n",
    "\n",
    "        if '(disambiguation)' in title:\n",
    "            continue\n",
    "\n",
    "        id_bag = id_counter(doc['identifiers'])\n",
    "        if len(id_bag) <= 1:\n",
    "            if len(id_bag) == 0:\n",
    "                empty = empty + 1\n",
    "            else:\n",
    "                small = small + 1\n",
    "            continue\n",
    "        \n",
    "        docs.append(doc)\n",
    "        titles.append(title)\n",
    "        ids.append(id_bag)\n",
    "\n",
    "        id_rels = rel_to_dict(doc['relations'])\n",
    "        rels.append(id_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5374, 1566)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty, small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22822\n"
     ]
    }
   ],
   "source": [
    "N_doc = len(titles)\n",
    "print N_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22822"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_idx = {title: idx for (idx, title) in enumerate(titles)}\n",
    "\n",
    "for doc, cats in doc_categories.items():\n",
    "    if doc in title_idx:\n",
    "        continue\n",
    "        \n",
    "    for cat in cats: \n",
    "        category_docs[cat].remove(doc)\n",
    "    \n",
    "    del doc_categories[doc]\n",
    "\n",
    "print len(doc_categories)\n",
    "\n",
    "title_cats = [doc_categories[title] for title in titles]\n",
    "doc_cat_flat = {}\n",
    "\n",
    "for line in file('C:/tmp/mlp/category_info.txt'):\n",
    "    title, cat = line.strip().split('\\t')\n",
    "    title = title.decode('utf-8')\n",
    "    cat = cat.decode('utf-8')\n",
    "    doc_cat_flat[title] = cat\n",
    "\n",
    "title_cats_flat = [doc_cat_flat[title] for title in titles]\n",
    "del doc_cat_flat\n",
    "print len(title_cats_flat)\n",
    "\n",
    "all_categories = list(set(title_cats_flat))\n",
    "categories_idx = {cat: idx for idx, cat in enumerate(all_categories)}\n",
    "title_cats_code = np.array([categories_idx[cat] for cat in title_cats_flat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discard infrequent identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12898"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = Counter()\n",
    "\n",
    "for id_cnt in ids:\n",
    "    all_ids.update(id_cnt)\n",
    "\n",
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10660"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infrequent = set()\n",
    "\n",
    "min_count = 20\n",
    "\n",
    "for (el, cnt) in all_ids.items():\n",
    "    if cnt <= min_count:\n",
    "        infrequent.add(el)\n",
    "\n",
    "len(infrequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for id_cnt in ids:\n",
    "    for id in list(id_cnt):\n",
    "        if id in infrequent:\n",
    "            del id_cnt[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.746823240732626"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(doc_ids) for doc_ids in ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove most common identifiers - based on df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = Counter()\n",
    "for cnt in ids:\n",
    "    for id in cnt:\n",
    "        df[id] = df[id] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n t x m p d g k f R l y c r T π C P b S s N B E F X j\n"
     ]
    }
   ],
   "source": [
    "top = 50\n",
    "mc = [id for (id, cnt) in df.most_common(top) if cnt > 3000]\n",
    "print ' '.join(mc)\n",
    "\n",
    "mc = set(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for id_cnt in ids:\n",
    "    for id in list(id_cnt):\n",
    "        if id in mc:\n",
    "            del id_cnt[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9679256857418279"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(doc_ids) for doc_ids in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({u't_i': 2, u't_k': 1, u'X_k': 1, u'X_i': 1, u'X_1': 1, u't_1': 1})"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some debug functions for printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ids(title):\n",
    "    if isinstance(title, (int, long)):\n",
    "        return ' '.join(ids[title])\n",
    "    else:\n",
    "        return ' '.join(ids[title_idx[title]])\n",
    "\n",
    "def print_ids(title):\n",
    "    print get_ids(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_2 Y_1 τ_i t_i t_n ε λ F_Y L Y_n U Y Z h t_0 t_1\n"
     ]
    }
   ],
   "source": [
    "print_ids(u'Laplace–Stieltjes transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_k t_i X_k X_i X_1 t_1\n"
     ]
    }
   ],
   "source": [
    "print_ids(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cluster_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(cluster_evaluation)\n",
    "evaluate = cluster_evaluation.Evaluator(doc_titles=titles, doc_ids=ids, doc_ids_definitions=rels, doc_categories=title_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_sets = [set(id_list) for id_list in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_jaccard(set1, set2):\n",
    "    union = len(set1 | set2)\n",
    "    if not union: \n",
    "        return 0.0\n",
    "\n",
    "    inter = len(set1 & set2)\n",
    "    return inter * 1.0 / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, to make it faster to compute the sim matrix, need to build the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inv_idx = {}\n",
    "\n",
    "for (idx, id_list) in enumerate(ids):\n",
    "    for id in id_list: \n",
    "        if id in inv_idx:\n",
    "            inv_idx[id].append(idx)\n",
    "        else:\n",
    "            inv_idx[id] = [idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def docs_to_compare(doc_id):\n",
    "    res = set([])\n",
    "    id_list = ids[doc_id]\n",
    "    for id in id_list:\n",
    "        res.update(inv_idx[id])\n",
    "    if doc_id in res:\n",
    "        res.remove(doc_id)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4759.9799999999996"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(docs_to_compare(doc_id)) for doc_id in xrange(200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usual algorithms like agglomerative are super long (they are super-linear, so it takes forever to compute them over the entire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_graph = 15\n",
    "k_matrix = 50\n",
    "sim_threshold = 0.5\n",
    "shared_nn = []\n",
    "\n",
    "jaccard_sim_matrix = scipy.sparse.dok_matrix((N_doc, N_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1000\n",
      "iteration 2000\n",
      "iteration 3000\n",
      "iteration 4000\n",
      "iteration 5000\n",
      "iteration 6000\n",
      "iteration 7000\n",
      "iteration 8000\n",
      "iteration 9000\n",
      "iteration 10000\n",
      "iteration 11000\n",
      "iteration 12000\n",
      "iteration 13000\n",
      "iteration 14000\n",
      "iteration 15000\n",
      "iteration 16000\n",
      "iteration 17000\n",
      "iteration 18000\n",
      "iteration 19000\n",
      "iteration 20000\n",
      "iteration 21000\n",
      "iteration 22000\n",
      "done in 634.224s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "for i in xrange(N_doc):\n",
    "    if i % 1000 == 0:\n",
    "        print \"iteration %d\" % i\n",
    "\n",
    "    doc_ids = np.array(list(docs_to_compare(i)))\n",
    "    sim = np.zeros(len(doc_ids))\n",
    "\n",
    "    for (idx, j) in enumerate(doc_ids):\n",
    "        sim[idx] = calc_jaccard(ids_sets[i], ids_sets[j])\n",
    "    \n",
    "    sim_idx = sim.argsort()[-1:-k_matrix-1:-1]\n",
    "    doc_ids_to_add = doc_ids[sim_idx]\n",
    "\n",
    "    shared_nn.append(set(doc_ids_to_add[0:k_graph]))\n",
    "    jaccard_sim_matrix[i, doc_ids_to_add] = sim[sim_idx]\n",
    "\n",
    "print \"done in %0.3fs.\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it's still too long to compute, it's $O(n^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jaccard_sim_matrix = scipy.sparse.coo_matrix(jaccard_sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          1.          0.66666667  0.66666667  0.66666667  0.66666667\n",
      "  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667  0.66666667\n",
      "  0.66666667  0.6         0.6         0.6         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.5         0.5         0.5       ]\n",
      "[20133  1370   303  2322 12775 16604 17787  9918 17956 20205 20525  2311\n",
      "   664 16082 18918 17174 19629 16292 16382 16427 17492 16608 19503 17843\n",
      " 15952 18414 19121 15980 13452 14846  9454   556   644  1189  2878  5879\n",
      "  6142  8025  8288 10064 13693 10176 10713 11333 11738 12025 12302 12546\n",
      "   549 21364]\n"
     ]
    }
   ],
   "source": [
    "row = jaccard_sim_matrix.getrow(11)\n",
    "print row.data[row.data.argsort()[::-1]]\n",
    "print row.indices[row.data.argsort()[::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB Scan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import snn_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 5000\n",
      "iteration 10000\n",
      "iteration 15000\n",
      "iteration 20000\n",
      "[('noise', 14375), ('16', 46), ('4', 37), ('18', 35), ('58', 33), ('2520', 33), ('2471', 32), ('2479', 30), ('2095', 29), ('2497', 29), ('244', 28), ('159', 28), ('2387', 28), ('2440', 27), ('2408', 27), ('2361', 27), ('2447', 26), ('2151', 26), ('2106', 26), ('2038', 26), ('2452', 25), ('2412', 25), ('2481', 25), ('2445', 24), ('533', 24), ('2430', 24), ('2404', 24), ('1821', 24), ('2416', 24), ('2136', 24), ('2207', 23), ('50', 23), ('2365', 23), ('338', 23), ('2128', 23), ('2483', 23), ('2460', 23), ('2325', 23), ('2453', 22), ('2462', 22), ('2382', 22), ('2389', 22), ('499', 22), ('2023', 22), ('124', 22), ('2458', 21), ('2508', 21), ('2494', 21), ('2466', 21), ('2469', 21)]\n"
     ]
    }
   ],
   "source": [
    "res = np.array(snn_dbscan.dbscan(shared_nn, 7, 6))\n",
    "print Counter(res).most_common()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res[res == 'noise'] = 0\n",
    "res = res.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10520550346157222"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.overall_purity(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': u'Bayer objects',\n",
       "  'cluster': 126,\n",
       "  'purity': 0.9056603773584906,\n",
       "  'size': 53},\n",
       " {'category': u'Stochastic processes',\n",
       "  'cluster': 157,\n",
       "  'purity': 0.8,\n",
       "  'size': 10}]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.high_purity_clusters(res, threshold=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(cluster_evaluation)\n",
    "evaluate = cluster_evaluation.Evaluator(doc_titles=titles, doc_ids=ids, doc_ids_definitions=rels, doc_categories=title_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 10\n",
      "\n",
      "Girsanov theorem (cats: Stochastic processes, Probability theorems) F_t E_P Ω X_t X_s W_t λ μ W_s σ Z_t Y_t Y_s Q W Y X_0\n",
      "Stochastic differential equation (cats: Differential equations, Stochastic processes, Stochastic calculus, Stochastic differential equations) f_i g_i Z X_t X_u μ σ D x_i u X_0 B_t\n",
      "Itō calculus (cats: Definitions of mathematical integration, Stochastic calculus) ξ_j ξ_k x_l x_m M Y_0 F_t X_T h_k M_t t_i H_s Ω σ_s X_t δ H_n μ X_s σ H J Y_t Y_s K x_k α_s x_j M_0 t_1 f_i π_n μ_s X_0 t_2 B_s B_t\n",
      "Quadratic variation (cats: Stochastic processes) Y_0 Δ V_t t_k C_p Ω σ_s X_v X_t X_u X_s μ_s Y_s σ H Y_t M c_p u X_0 v B_s\n",
      "Bessel process (cats: Stochastic processes) Z_t X_t W_t\n",
      "Novikov's condition (cats: Stochastic processes, Martingale theory) Ω F_t X_t X_s W_t W_s\n",
      "Semimartingale (cats: Stochastic processes, Martingale theory) Δ σ_s H X_T X_t X_0 b_s W_s M_t\n",
      "Tanaka equation (cats: Equations, Stochastic differential equations) X_t sgn B_t X_s\n",
      "Filtering problem (stochastic processes) (cats: Control theory, Stochastic processes, Signal processing, Estimation theory, Stochastic differential equations) H_t Σ H_s Ω G_t γ X_t W_t σ Z_t K Y_t L Y Z B_t\n",
      "Dudley's theorem (cats: Stochastic processes, Entropy, Probability theorems) d_X X_s X_t ε\n",
      "\n",
      "common terms: (X_t)\n",
      "top categories: [(u'Stochastic processes', 8), (u'Stochastic differential equations', 3), (u'Martingale theory', 2), (u'Stochastic calculus', 2), (u'Probability theorems', 2)]\n",
      "purity: 0.800\n",
      "relations:\n",
      "    B: (Brownian motion: 19.33), (form: 6.31), (Wiener process: 5.30), (proof: 3.55), (version: 3.27), (filtration: 2.99), (initial condition X_0: 1.20)\n",
      "    B_t: (properties: 4.46), (variance Var: 0.97)\n",
      "    C: (constants: 12.17)\n",
      "    D: (constants: 5.71)\n",
      "    E: (conditional expectation operator: 1.77), (martingales: 1.17)\n",
      "    F: (filtration: 3.48), (conditional expectation operator: 1.70), (sub-σ-algebra: 0.62), (conditional expectations: 0.62)\n",
      "    F_t: (information: 3.64), (sigma algebra: 2.31)\n",
      "    G_t: (observations: 4.37), (& sigma ; - algebra: 2.61)\n",
      "    H: (process: 9.40), (integrand: 2.77), (semimartingale: 1.90), (linearity: 1.66), (predictable process: 1.61), (adapted: 1.42), (integrable martingale: 1.04), (càdlàg square: 0.98)\n",
      "    H_t: (observations: 5.20)\n",
      "    K: (space: 6.43), (linear subspace: 3.14), (candidates: 2.19)\n",
      "    L: (orthogonal projection: 3.48)\n",
      "    M: (local martingale: 7.89), (quadratic variation: 2.01), (jumps: 1.79), (predictable process: 1.57), (càdlàg square: 0.91), (ΔM ^: 0.60)\n",
      "    M_0: (deterministic calculus: 0.56)\n",
      "    P: (partition: 9.15), (probability measure: 4.34), (norm: 4.15), (filtration: 3.15), (martingale: 2.45), (mesh: 1.69), (canonical measure: 0.66), (density transformation: 0.61), (partitions of the interval: 0.60)\n",
      "    Q: (measure: 5.84), (martingale: 2.81)\n",
      "    R: (Euclidean space: 10.53), (dimensiona: 7.82), (observations: 4.53)\n",
      "    T: (Gaussian process: 2.48), (pseudometric: 1.85)\n",
      "    W: (Brownian motion: 3.76), (continuous process: 0.98)\n",
      "    W_t: (Brownian motion: 7.07), (measure: 4.95), (process: 4.17), (probability space: 2.99), (Wiener: 2.95)\n",
      "    X: (process: 19.22), (components: 5.03), (processes: 3.60), (Brownian motion: 3.58), (filtration: 3.10), (quadratic variation: 1.81), (semimartingale: 1.72), (continuous process: 0.92), (finite variation process: 0.91), (Doléans exponential: 0.60), (n-valued process: 0.57)\n",
      "    X_0: (process: 4.63)\n",
      "    X_t: (stochastic process: 14.53), (process: 10.03), (variance: 4.65), (expectation: 3.61), (quadratic variation: 1.96), (continuous time: 1.78), (adapted: 1.30), (left limit: 1.27), (with probability one: 0.64), (ΔX_t: 0.63), (sup_s: 0.62), (measurable process: 0.60)\n",
      "    Y: (local martingale: 1.60)\n",
      "    Y_t: (state: 6.00), (system: 5.34), (random variable: 5.26), (process: 4.94), (true state: 1.79), (local martingale: 1.49)\n",
      "    Z: (space: 5.82), (random variable: 4.80), (filtration: 3.15), (linear subspace: 2.84)\n",
      "    Z_t: (observations: 5.20), (integral representation: 1.12)\n",
      "    b: (Brownian motion: 3.81)\n",
      "    c: (constants: 6.47), (initial condition X_0: 1.21)\n",
      "    d_X: (Gaussian process: 2.48), (pseudometric: 1.74)\n",
      "    f: (differentiable function: 3.58)\n",
      "    f_i: (unknowns: 3.15)\n",
      "    g_i: (constants: 5.84)\n",
      "    l: (Euclidean space: 5.43), (dimensiona: 4.46)\n",
      "    n: (Euclidean space: 9.52), (dimensiona: 8.32), (order: 6.37), (system: 5.43), (state: 5.40), (process: 4.63), (real parameter: 2.55), (Bessel: 2.15), (real-valued: 1.79), (drift field: 0.94), (Itō SDEs: 0.56)\n",
      "    p: (real number: 5.56)\n",
      "    predictable: (process: 5.11), (processes: 3.74), (finite variation process: 1.01)\n",
      "    r: (Radon -- Nikodym derivative: 1.82), (free rate: 1.61), (instanteaneous risk: 0.98)\n",
      "    s: (Brownian motion: 10.94), (stochastic processe: 9.11), (dynamics: 2.77), (analysis: 2.56), (predictable processe: 2.44), (calculus: 1.68), (Poisson processe: 1.06), (Itō processe: 0.64)\n",
      "    sgn: (sign function: 2.59), (unconventional value: 0.66)\n",
      "    simple: (process: 4.73), (processes: 3.58), (predictable processe: 1.34)\n",
      "    t: (time: 20.84), (random variable: 9.46), (measure: 5.41), (variance: 4.55), (interest: 3.70), (quadratic variation: 2.01), (time index: 1.97), (t-continuous solution: 0.62)\n",
      "    x_k: (Itōs lemma: 1.24)\n",
      "    Δ: (jumps: 2.00)\n",
      "    Σ: (probability space: 2.77)\n",
      "    Ω: (random variable: 4.80), (probability space: 3.18)\n",
      "    ε: (radius: 6.77), (entropy number: 0.62), (d_X-balls: 0.62)\n",
      "    η_m: (time: 7.23), (random function: 1.74), (physics formulation: 0.58)\n",
      "    μ: (expectation: 4.19), (normally distributed: 2.67), (free rate: 1.85), (assets drift: 1.04), (instanteaneous risk: 0.98)\n",
      "    ξ_j: (white noise: 2.36)\n",
      "    π_n: (sequence: 5.53)\n",
      "    σ: (variance: 5.39), (volatility: 3.38), (assets drift: 1.04), (drift field: 0.96), (drift coefficient: 0.57)\n"
     ]
    }
   ],
   "source": [
    "evaluate.print_cluster(res, 157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 6\n",
      "\n",
      "Covariant formulation of classical electromagnetism (cats: Special relativity, Concepts in physics, Electromagnetism) D_z J_free D_x L_int E_z E_y E_x J_β M_z M_y M_x u_α E_j E_i u D q H_z μ_0 H_x H_y α γ β D_y f_α η H ρ_free P_z λ ν μ δ ρ σ τ χ_m S_y S_x J S_z M L L_field ϕ P_x x_ν p_α B_i B_j χ_e ϵ ρ_bound B_x B_y B_z ϵ_0 J_bound P_y z u_ν\n",
      "Electromagnetic tensor (cats: Tensors in general relativity, Theory of relativity, Tensors, Minkowski spacetime, Electromagnetism) ϵ_0123 E_z E_y E_x ℏ E_i B_x B_y D_α γ α μ_0 β δ ϵ ν μ ρ τ G ψ J L B_i B_k q B_z ϵ_0 u\n",
      "Mathematical descriptions of the electromagnetic field (cats: Mathematical physics, Electromagnetism) E_z E_y E_x σ γ_μ Γ ε_0 j_x j_y Λ j_z γ_1 γ_0 γ_3 γ_2 ∇_α γ ∇_γ ∇_β σ_1 σ_3 β δ η θ λ ν μ ρ σ_2 G φ ψ J σ_k μ_0 B_x B_y B_z ϵ_0 q α γ_k z\n",
      "Classical electromagnetism and special relativity (cats: Special relativity, Electromagnetism) ϵ E_⊥ E_z E_y E_x B_∥ J_z Λ q J_y φ μ_0 α γ β δ J_x u_z λ u_x ν μ ρ D G H J B_⊥ x_β E_∥ x_α u_y J_⊥ J_∥ B_x B_y B_z ϵ_0 u v z\n",
      "Lorentz covariance (cats: Special relativity, Symmetry) E_z E_y E_x p_z Δ p_x p_y j_x j_y j_z B_y B_z γ δ η m_0 ν μ ρ τ U B_x ϵ z\n",
      "Lorentz force (cats: Concepts in physics, Electromagnetism) Φ_B E_z E_y E_x U_3 U_β U_1 U_0 p_z p_x p_y Λ F_x B_SI γ_0 q_SI B_cgs E_cgs μ_0 α γ β u_z u_y u_x ν μ ρ σ τ J L ϕ V p_2 p_3 p_0 p_1 q_cgs E_SI ∇_x U_2 B_x B_y B_z ϵ_0 u q v z\n",
      "\n",
      "common terms: (ρ E_z E_y E_x γ B_x B_y B_z ν μ)\n",
      "top categories: [(u'Electromagnetism', 5), (u'Special relativity', 3), (u'Concepts in physics', 2), (u'Symmetry', 1), (u'Minkowski spacetime', 1)]\n",
      "purity: 0.833\n",
      "relations:\n",
      "    B: field, magnetic field, E/c →\n",
      "    D: fields, magnetic intensity\n",
      "    E: field, electric field, magnetic field, transformations\n",
      "    E_∥: fields\n",
      "    F: stress-energy tensor, indices, differential 2-form, force, tensor\n",
      "    G: dual tensor\n",
      "    H: fields, electromagnetic displacement tensor\n",
      "    J: Maxwells equations, components, current density, 4-current, currents\n",
      "    L: electromagnetic Lagrangian density\n",
      "    M: fields\n",
      "    P: fields\n",
      "    S: electromagnetic stress-energy tensor\n",
      "    T: stress-energy tensor, general relativity\n",
      "    c: speed, neglect, speed of light\n",
      "    d: flat reference connection\n",
      "    f: force density, charged particle\n",
      "    g: metric tensor\n",
      "    m: charge\n",
      "    p: constitutive relation, covariant form\n",
      "    p_α: four-momentum\n",
      "    q: velocity, charge, electric charge\n",
      "    r: position vector\n",
      "    t: seconds, magnitude, magnetic field\n",
      "    u: particular case, 4-velocity\n",
      "    v: relative velocity, velocity\n",
      "    x: coloumbs\n",
      "    y: directions\n",
      "    z: yields\n",
      "    Φ_B: different B-field\n",
      "    α: calculation, 1-forms dx ^, 4-current\n",
      "    β: position, Faradays Law\n",
      "    γ: relativistic factor, Lorentz\n",
      "    γ_0: arbitrary time-direction\n",
      "    η: diag, Minkowski metric\n",
      "    θ: basis forms\n",
      "    λ: time\n",
      "    μ_0: magnetic permeability of vacuum, vacuum permeability\n",
      "    π: Kronecker delta\n",
      "    ρ: motion, charges, charge density, current density\n",
      "    σ: turn, electrical conductivity\n",
      "    τ: proper time\n",
      "    φ: magnetic potential, potentials\n",
      "    χ_e: electric susceptibility\n",
      "    χ_m: magnetic susceptibility\n",
      "    ϕ: electrostatic potential\n"
     ]
    }
   ],
   "source": [
    "evaluate.print_cluster(res, 2414)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 6\n",
      "\n",
      "Orthotropic material (cats: Materials, Continuum mechanics) Δ_k c_1212 c_1211 ν_13 ε_12 K_11 K_13 K_12 E_i S_44 c_2333 c_3311 c_3312 d_2 d_3 d_1 C_66 σ_1 σ_3 σ_2 ε σ_4 σ_6 G_13 G_12 E_3 E_2 E_1 D H S_23 c_1111 c_1112 Δ_2 Δ_3 Δ_1 Δ_6 Δ_4 Δ_5 c_3322 c_3323 S_55 ε_11 c_3122 c_3123 c_2233 d_j c_1231 c_1233 c_2323 c_2322 c_1122 c_1123 f_i C_46 C_44 C_45 σ_12 ε_22 ε_23 σ_22 σ_23 c_3131 c_3133 c_3333 ν_12 c_3331 ε_3 ε_2 ε_1 ε_6 ε_5 ε_4 κ K c_1223 c_1222 c_2212 C_55 C_56 σ_33 ν_23 ν_21 ε_31 c_2211 ε_33 c_2222 S_33 c_2223 G_ij c_3112 c_3111 ν_31 ν_32 C_24 C_25 C_26 C_22 C_23 c_1133 f_1 c_1131 f_3 σ_5 σ f_2 J C_36 C_35 C_34 C_33 σ_31 σ_11 K_21 K_22 K_23 G_23 v S_11 S_13 S_12 C_11 η_μ ν_ij K_33 K_32 K_31 G_31 μ S_66 S_22 c_2331 c_2231 S_k c_2312 c_2311 C_15 C_14 C_16 C_13 C_12 q\n",
      "Vibration of plates (cats: Continuum mechanics) x_α Δ C_n J_0 ε_22 ω_n σ_22 J_1 u_i φ C_1 C_2 M_22 λ ν μ ρ D ω ψ β x_2 x_3 W x_1 U ε_12 J_3 ε_11 B_n λ_n h σ_11 σ_12 q u_α w x_β M_12 M_11\n",
      "Mindlin–Reissner plate theory (cats: Continuum mechanics) φ_β ε_31 ε_12 Γ σ_32 C_44 M_21 C_12 φ_α D ε_22 ε_23 C_22 σ_23 Ω Ψ φ_1 C_66 α σ_31 β δ M_22 ϵ κ ν σ Q_1 G K N_22 M n_α n_β Q C_55 x_3 φ_2 x_1 w U ε_32 M_11 V_ext σ_33 σ_22 ε_11 h Φ σ_11 C_11 ε_33 σ_12 u_3 u_α u Q_2 Q_α x_2 N_12 M_12 q N_11\n",
      "Stress resultants (cats: Mechanics, Solid mechanics, Composite materials) σ_22 σ_23 N_22 M_22 F_1 x_2 x_3 F_2 M_2 M_1 V_1 V_2 V_3 N_12 σ_11 σ_13 σ_12 M_13 M_12 M_11 N_11\n",
      "Plate theory (cats: Continuum mechanics) C_66 α N_22 m_3 m_2 m_1 G_12 ν ρ E_2 E_1 D n_α n_β φ_α θ_x ε_12 ε_11 D_32 D_33 D_31 J_1 u_α J_3 h N_12 N_11 C_44 D_21 D_23 D_22 ε_22 ε_23 σ_22 σ_23 ν_12 β κ G m_x x_β W x_α σ_33 σ_32 σ_31 ν_21 ε_31 ε_33 ε_32 Q_2 Q_1 C_55 M_12 M_11 φ_1 D_x D_y φ_2 w_x C_22 C_23 M_22 x_2 x_3 x_1 C_33 σ_11 σ_12 Q_α z n_x D_12 D_13 q_x P_n u_3 u_i θ P_t P_q w n_1 n_2 n_3 U q_2 q_1 C_11 D_11 C_13 C_12 q u\n",
      "Kirchhoff–Love plate theory (cats: Continuum mechanics) ϵ C_11 x_1 x_i Γ ε_33 σ_12 ε_22 q C_22 C_23 Ω u_i ε_11 φ_α α N_22 N_21 β δ J_1 M_22 θ V_ext ν ρ σ D J_3 H K M n_α n_β u_α x_2 x_3 x_α σ_33 w U ε_12 J_2 C_33 σ_22 h σ_11 C_13 C_12 u_3 u_2 u_1 u Q_α u_β x_β z N_12 M_12 M_11 N_11\n",
      "\n",
      "common terms: (σ_11 σ_22 σ_12)\n",
      "top categories: [(u'Continuum mechanics', 5), (u'Mechanics', 1), (u'Materials', 1), (u'Composite materials', 1), (u'Solid mechanics', 1)]\n",
      "purity: 0.833\n",
      "relations:\n",
      "    B: theory\n",
      "    B_n: conditions\n",
      "    C: matrix\n",
      "    C_1: appropriate boundary condition\n",
      "    C_2: constants\n",
      "    D: stiffness\n",
      "    E: modulus, Youngs\n",
      "    E_i: Youngs modulus\n",
      "    G_ij: shear modulus\n",
      "    J_0: order\n",
      "    K: matrix\n",
      "    N_11: membrane force\n",
      "    S: submatrix\n",
      "    S_k: principal\n",
      "    V_2: membrane force\n",
      "    V_3: shear forces\n",
      "    W: first variation\n",
      "    b: width, dimensions\n",
      "    c: stiffness tensor\n",
      "    h: uniform thickness, plate thickness, thickness\n",
      "    j: extension\n",
      "    n: mode\n",
      "    n_α: effective shear force\n",
      "    p: mode k\n",
      "    q: out-of-plane load, external force, unit area\n",
      "    r: appropriate boundary condition\n",
      "    s: deformations\n",
      "    t: right hand side, width\n",
      "    u: pure bending\n",
      "    u_α: plate, Taylor series\n",
      "    w: moments, theory, w_xxw_yy −, displacement\n",
      "    x: undeformed plate, boundary conditions\n",
      "    x_1: plate, form, out-of-plane\n",
      "    x_2: plate, plane, dimensions\n",
      "    x_3: plates, thickness direction, direction, mid-surface\n",
      "    y: unit width\n",
      "    Φ: biharmonic function\n",
      "    Ψ: Laplace\n",
      "    α: index\n",
      "    ε: strain tensor\n",
      "    κ: shear correction factor\n",
      "    λ: previous expression\n",
      "    ν: ratio\n",
      "    ν_ij: Poissons ratio\n",
      "    ρ: homogeneous mass density, thickness\n",
      "    σ: tensor\n",
      "    φ_1: quantities\n",
      "    φ_2: angles\n",
      "    φ_α: plate theory, angles\n",
      "    ω_n: first term\n"
     ]
    }
   ],
   "source": [
    "evaluate.print_cluster(res, 2045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027101848041983765"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_mutual_info_score(title_cats_code, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhash "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use minhash to speed up computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://github.com/ekzhu/datasketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasketch.minhash import MinHash, jaccard\n",
    "from hashlib import sha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsh_hashes = 8\n",
    "hash_len = 4\n",
    "digest_len = lsh_hashes * hash_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digest(id_list):\n",
    "    m = MinHash(num_perm=digest_len)    \n",
    "    for i in id_list:\n",
    "        m.digest(sha1(i.encode('utf8')))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minhashes = [digest(id_list) for id_list in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chunks(lst, n):\n",
    "    for i in xrange(0, len(lst), n):\n",
    "        yield tuple(lst[i:i+n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_minhash_buckets(doc_id, n):\n",
    "    chunks = get_chunks(minhashes[doc_id].hashvalues, n)\n",
    "    return [hash(chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minhash_index = {}\n",
    "\n",
    "for doc_id in xrange(len(ids)):\n",
    "    for bucket in calc_minhash_buckets(doc_id, n=hash_len):\n",
    "        if bucket in minhash_index:\n",
    "            minhash_index[bucket].append(doc_id)\n",
    "        else: \n",
    "            minhash_index[bucket] = [doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8484254772068531"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(val) for val in minhash_index.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can query it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_minhash_index(query_doc_id):\n",
    "    candidates = set([])\n",
    "    for bucket in calc_minhash_buckets(query_doc_id, n=hash_len):\n",
    "        if bucket in minhash_index:\n",
    "            candidates.update(minhash_index[bucket])\n",
    "    if query_doc_id in candidates:\n",
    "        candidates.remove(query_doc_id)\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263.94"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(query_minhash_index(idx)) for idx in xrange(200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to do jaccard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_doc = len(ids)\n",
    "jaccard_sim_matrix = scipy.sparse.dok_matrix((N_doc, N_doc), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'coo_matrix' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-57d9c59e7019>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mjaccard_sim_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mjaccard_sim_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjaccard_sim_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_jaccard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'coo_matrix' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "for i in xrange(N_doc):\n",
    "    if i % 10000 == 0:\n",
    "        print \"iteration %d\" % i\n",
    "    docs = query_minhash_index(idx)\n",
    "    \n",
    "    for j in docs:\n",
    "        if jaccard_sim_matrix[i, j] == 0.0:\n",
    "            jaccard_sim_matrix[i, j] = jaccard_sim_matrix[j, i] = calc_jaccard(ids_sets[i], ids_sets[j])\n",
    "\n",
    "print \"done in %0.3fs.\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jaccard_sim_matrix = scipy.sparse.coo_matrix(jaccard_sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True jaccard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row_id = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_compare = list(docs_to_compare(row_id))\n",
    "jaccard_real = np.zeros(len(to_compare))\n",
    "\n",
    "for j, idx_other in enumerate(to_compare):\n",
    "    jaccard_real[j] = calc_jaccard(ids_sets[row_id], ids_sets[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.41176471  0.27777778  0.26666667  0.25        0.25        0.25\n",
      "  0.23809524  0.23076923  0.23076923]\n",
      "Newton–Euler equations\n",
      "c τ F ω m α p v_cm c_y c_x c_z\n",
      "\n",
      "0.41 AC power P_inst RMS Q_c Q_b Q_a k_1 k_2 P_b P_c P_a S_a P_avg V_RMS P S R ϕ V X Q f k j m S_c n p S_b t t_2 t_1 ω_2 ω_1\n",
      "0.28 Angle of view S_1 π FOV S_2 d P f h α_d F m L α_h α α_v f_c v D\n",
      "0.27 Calculus of moving surfaces Γ ∇_η ∇_α ∇_β α γ β ε δ η N_i C B S_t F N P S T Z h k j m p ∇_i t v\n",
      "0.25 Conformal symmetry K_ν D m P_ρ p P_μ P_ν K_ρ x x_μ x_ν ν μ K_μ\n",
      "0.25 Negation p b ¬\n",
      "0.25 Permutation polynomial p_i k_t p_t q Σ k_1 k_2 α t M L α_s Z p_1 c b d g j m l o n k_i p s r k_l y x\n",
      "0.24 Stokes operator w_k P_σ Ω α γ λ_1 λ_3 λ_2 C D H L R V λ λ_k g k l n u_k u t\n",
      "0.23 Lagrangian mechanics j y_pend q_m V q_j q_i L_rel q_1 n x Q_j r_i r_j pend N_i N_j r_n θ λ V_i δ D F J M L F_i y S R x_2 T W x_1 L_cm λ_i m_i d g r_1 r_2 r_3 m l F_cf μ q p r t t_2 U t_1 k q_2\n",
      "0.23 Differential coding z F h k m l x_i p u_0 u t y_i H y x y_0\n"
     ]
    }
   ],
   "source": [
    "print jaccard_real[jaccard_real.argsort()][-2:-11:-1]\n",
    "\n",
    "print titles[row_id]\n",
    "print_ids(row_id)\n",
    "print \n",
    "\n",
    "for idx in jaccard_real.argsort()[-2:-11:-1]:\n",
    "    print '%0.2f' % jaccard_real[idx], titles[to_compare[idx]], \n",
    "    print_ids(to_compare[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSH index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Newton–Euler equations\n",
      "c τ F ω m α p v_cm c_y c_x c_z\n",
      "\n",
      "0.16 Fiducial inference all F ω l n α P observations x X t\n",
      "0.16 Cavity ring-down spectroscopy c τ τ_0 C l α R ϵ t X n\n",
      "0.16 Inverse Mills ratio σ g Φ m l α p ϕ t X μ\n",
      "0.15 Bigraph c E k m l n p r t V Y X\n",
      "0.14 Transposable integer d F N_c k j m l N p s t X n D\n",
      "0.13 Truncated normal distribution Φ α β δ λ μ ξ π σ F N ϕ X Z U b g f m l p t x\n",
      "0.12 Mode (statistics) σ g P θ k m l x_i α p μ_0 t X x n ν μ\n",
      "0.11 Sparse matrix m l x_i p N n t X Z\n",
      "0.11 Anderson–Darling test σ p d Φ F_n F m l Y_1 X_i W Y_n S t Y_i X x w n μ\n",
      "0.11 Midpoint circle algorithm C E β g p h m l x_i α y_n r t y_i X y x R n Y\n",
      "0.11 Cantelli's inequality Pr σ g m l p t X λ μ\n"
     ]
    }
   ],
   "source": [
    "row = jaccard_sim_matrix.getrow(row_id)\n",
    "\n",
    "print titles[row_id]\n",
    "print_ids(row_id)\n",
    "\n",
    "order = row.data.argsort()[:-12:-1]\n",
    "\n",
    "print \n",
    "for i, jac in zip(row.indices[order], row.data[order]):\n",
    "    print '%0.2f'% jac, titles[i], \n",
    "    print_ids(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll remove low-freq words, but will keep high-freq (idf will take care of that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = [id_counter(d['identifiers']) for d in docs]\n",
    "\n",
    "all_ids = Counter()\n",
    "\n",
    "for id_cnt in ids:\n",
    "    all_ids.update(id_cnt)\n",
    "\n",
    "infrequent = set()\n",
    "min_count = 15\n",
    "\n",
    "for (el, cnt) in all_ids.items():\n",
    "    if cnt <= min_count:\n",
    "        infrequent.add(el)\n",
    "\n",
    "for id_cnt in ids:\n",
    "    for id in (set(id_cnt) & infrequent):\n",
    "        del id_cnt[id]\n",
    "\n",
    "del all_ids\n",
    "del infrequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unwrap_counter(cnt):\n",
    "    res = []\n",
    "    for id, c in cnt.items():\n",
    "        res.extend([id] * c)\n",
    "    return res\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=unwrap_counter)\n",
    "X = vectorizer.fit_transform(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22822, 2729)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "U, S, Vt = randomized_svd(X, n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22822L, 100L), (100L,), (100L, 2729L))"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape, S.shape, Vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V = Vt.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V_neg = V.sum(axis=0) < 0\n",
    "V[:, V_neg] = -V[:, V_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(V.T.dot(V), np.eye(n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic #1\n",
      "b: 0.48, k: 0.32, f: 0.29, d: 0.29, y: 0.24, t: 0.21, m: 0.19, p: 0.17, n: 0.16, x: 0.15,\n",
      "\n",
      "topic #2\n",
      "Ω: -0.56, U: 0.47, d: 0.46, k: -0.30, f: 0.15, n: -0.12, y: 0.09, p: -0.07, m: 0.06, x: 0.05,\n",
      "\n",
      "topic #3\n",
      "S: 0.47, R: -0.40, r: -0.35, t: -0.31, k: -0.20, y: 0.17, x: 0.15, m: 0.12, p: 0.11, n: 0.11,\n",
      "\n",
      "topic #4\n",
      "T: -0.68, S: 0.23, c: 0.20, L: -0.18, G: 0.18, d: 0.15, x: 0.13, r: 0.12, t: 0.12, n: 0.11,\n",
      "\n",
      "topic #5\n",
      "F: -0.48, C: 0.31, s: 0.30, d: -0.23, S: 0.22, B: 0.17, r: -0.17, P: -0.16, X: 0.15, t: 0.15,\n",
      "\n",
      "topic #6\n",
      "ω: 0.65, θ: 0.41, z: -0.30, x: -0.15, k: 0.15, r: -0.13, X: -0.10, t: 0.10, c: 0.09, b: -0.09,\n",
      "\n",
      "topic #7\n",
      "y: -0.43, x: -0.37, R: 0.37, P: -0.30, Y: -0.23, t: -0.21, b: 0.18, r: 0.16, X: 0.13, f: 0.10,\n",
      "\n",
      "topic #8\n",
      "B: -0.50, π: 0.34, b: -0.33, k: -0.19, f: 0.19, S: -0.18, θ: -0.18, X: 0.14, t: -0.14, r: 0.14,\n",
      "\n",
      "topic #9\n",
      "α: 0.43, d: -0.42, h: 0.37, t: 0.30, r: -0.17, Y: -0.16, k: -0.16, z: 0.14, X: -0.12, f: 0.11,\n",
      "\n",
      "topic #10\n",
      "Z: -0.50, B: 0.46, T: 0.29, R: 0.19, X: -0.18, r: 0.16, y: -0.14, z: 0.12, k: -0.12, f: 0.12,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "# U here is term-term matrix because we did svd on tfidf.T - i.e. on term-doc matrix, not doc-term\n",
    "\n",
    "for topic_id in xrange(10):\n",
    "    print 'topic #%d' % (topic_id + 1)\n",
    "    topic = V[:, topic_id]\n",
    "    indices = np.abs(topic).argsort()[::-1][:10]\n",
    "    contribution = topic[indices]\n",
    "    for idx, contrib in zip(np.nditer(indices), np.nditer(contribution)):\n",
    "        print '%s: %0.2f,' % (terms[idx], contrib),\n",
    "    print\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22822L, 100L)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_red = X.dot(V)\n",
    "X_red.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to use cosine through euclidean, but for that need to normalize row-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66399702893712997"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_red[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_red = normalizer.fit_transform(X_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999999989"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_red[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=50, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(X_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centroids = km.cluster_centers_.dot(Vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:  B  C  S  E  p  P  c  n  R  Ω\n",
      "Cluster 1:  y  x  z  d  b  t  p  f  n  r\n",
      "Cluster 2:  c  o  t  r  n  l  p  m  s  b\n",
      "Cluster 3:  h  g  f  λ  n  c  x_0  k  m  t\n",
      "Cluster 4:  D  C  E  T  R  P  G  L  F  o\n",
      "Cluster 5:  f  x  g  t  b  n  y  d  h  Y\n",
      "Cluster 6:  X  Y  f  Z  B  x  p  δ  P  t\n",
      "Cluster 7:  r  d  π  t  c  n  m  x  θ  k\n",
      "Cluster 8:  O  H_2  H  O_2  x_i  N  V  P  C  G\n",
      "Cluster 9:  G  g  K  F  ϕ  V  t  k  r  S\n",
      "Cluster 10:  T  k  S  k_B  d  R  n  μ  N  x\n",
      "Cluster 11:  j  l  k  n  m  t  g  x  ℏ  σ\n",
      "Cluster 12:  σ  τ  μ  t  T  n  x  j  π  θ\n",
      "Cluster 13:  L  γ  μ  K  ν  n  t  g  δ  β\n",
      "Cluster 14:  α  β  x  n  m  γ  k  l  ϵ  g\n",
      "Cluster 15:  ρ  L  V  v  d  x  k  g  Δ  θ\n",
      "Cluster 16:  x  t  p  d  n  y  m  f  u  b\n",
      "Cluster 17:  F  G  x  E  S  C  X  N  k  P\n",
      "Cluster 18:  b  c  x  d  n  y  f  m  p  J\n",
      "Cluster 19:  x  y  n  f  d  t  b  π  m  u\n",
      "Cluster 20:  k  n  t  m  p  x  π  Z  g  f\n",
      "Cluster 21:  u  v  x  p  t  X  y  h  g  j\n",
      "Cluster 22:  s  t  n  m  r  p  x  k  π  d\n",
      "Cluster 23:  p  m  n  x  U  k  c  t  u  α\n",
      "Cluster 24:  n  O  k  ϵ  x  U  x_i  V  P  Ω\n",
      "Cluster 25:  Q  P  c  L  S  q  R  V  n  Φ\n",
      "Cluster 26:  q  p  n  x  m  t  g  r  l  Δ\n",
      "Cluster 27:  λ  x  h  μ  D  π  ϵ  t  ν  Ω\n",
      "Cluster 28:  H  K  p  P  M  k  T  G  c  O_2\n",
      "Cluster 29:  X  Y  n  u  U  P  x  p  k  K\n",
      "Cluster 30:  S  B  ϵ  T  R  x  U  G  δ  k\n",
      "Cluster 31:  v  u  m  p  c  t  x  γ  R  f\n",
      "Cluster 32:  N  n  α  C  t  F  R  T  d  S\n",
      "Cluster 33:  Δ  l  k  T  t  d  R  v  D  π\n",
      "Cluster 34:  t  x  d  l  τ  n  k  s  u  f\n",
      "Cluster 35:  P  x  B  m  Q  X  R  T  D  n\n",
      "Cluster 36:  d  t  x  r  n  L  p  T  E  m\n",
      "Cluster 37:  C  n  K  B  F  m  N  t  D  M\n",
      "Cluster 38:  ϕ  ψ  x  G  T  r  R  v  c  β\n",
      "Cluster 39:  M  T  H  d  R  N  L  C  k  x\n",
      "Cluster 40:  θ  r  d  c  x  n  D  s  σ  g\n",
      "Cluster 41:  ω  t  d  Ω  π  n  x  c  F  ϵ\n",
      "Cluster 42:  E  c  m  L  B  d  r  F  W  V\n",
      "Cluster 43:  z  n  f  x  k  w  t  g  p  d\n",
      "Cluster 44:  n  x  k  p  m  t  g  b  R  C\n",
      "Cluster 45:  m  n  p  k  x  t  r  c  j  α\n",
      "Cluster 46:  V  E  P  S  G  p  R  n  j  x\n",
      "Cluster 47:  π  c  r  x  τ  n  k  μ  ℏ  d\n",
      "Cluster 48:  x_1  x_2  x_n  x  n  x_i  f  x_0  p  x_3\n",
      "Cluster 49:  R  n  S  t  x  r  D  m  ¬  N\n"
     ]
    }
   ],
   "source": [
    "order_centroids = centroids.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i in range(50):\n",
    "    print \"Cluster %d:\" % i,\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print ' %s' % terms[ind],\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 421,  899,  399,  309,  288,  609,  349,  644,  160,  379,  508,\n",
       "        266,  266, 1268,  492,  349,  610,  313,  539,  751,  508,  423,\n",
       "        450, 1177,  169,  292,  408,  364,  230,  480,  373,  337,  441,\n",
       "        375,  774,  434,  548,  291,  290,  477,  418,  363,  315,  458,\n",
       "        960,  455,  388,  199,  237,  369], dtype=int64)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054346625108437144"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.overall_purity(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.high_purity_clusters(km.labels_, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05487087256729932"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_mutual_info_score(title_cats_code, km.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Scatter/Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S/G is k-means with\n",
    "\n",
    "- seed selection (buckshot: do hierarchical clustering on sample of $\\sqrt{n}$)\n",
    "- k-means, but centrod is concatenation of all docs in the cluster\n",
    "- refinement operations\n",
    "\n",
    "For tf-idf can just sum two vectors: $\\text{tf}(t_i, d_1) \\cdot \\text{idf}(t_i) + \\text{tf}(t_i, d_2) \\cdot \\text{idf}(t_2) = \\Big( \\text{tf}(t_i, d_1) + \\text{tf}(t_i, d_2) \\Big) \\cdot \\text{idf}(t_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buckshot():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means implementation: \n",
    "\n",
    "- http://codereview.stackexchange.com/questions/61598/k-mean-with-numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_centroids(X, clusters, k):\n",
    "    result = []\n",
    "    \n",
    "    cluster_no = 0\n",
    "\n",
    "    for i in xrange(k):\n",
    "        if (clusters == i).sum() == 0:\n",
    "            continue\n",
    "\n",
    "        centroid = X[clusters == i].mean(axis=0)\n",
    "        result.append(np.array(centroid).flatten())\n",
    "        cluster_no = cluster_no + 1\n",
    "\n",
    "    return np.array(result), cluster_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmeans(X, k, centroids=None, steps=20):\n",
    "    if not centroids:\n",
    "        centroids = X[np.random.choice(np.arange(X.shape[0]), size=k)]\n",
    "\n",
    "    for _ in xrange(steps):\n",
    "        D = euclidean_distances(centroids, X)\n",
    "        clusters = D.argmin(axis=0)\n",
    "\n",
    "        new_centroids, k = cluster_centroids(X, clusters, k)\n",
    "        # need other stop criterion\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return clusters, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    }
   ],
   "source": [
    "res, k_final = kmeans(X_red, k=300)\n",
    "print k_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12249381557435336"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.overall_purity(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': u'Bayer objects', 'cluster': 99, 'purity': 0.875, 'size': 56}]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.high_purity_clusters(res, threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057591819742542349"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_mutual_info_score(title_cats_code, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  K-means cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0... J=5.2162\n",
      "step 10... J=0.0004\n",
      "converged after step=19, final J=0.0015\n",
      "496\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(300)\n",
    "res, k_final = kmeans.kmeans(X_red, k=500)\n",
    "print k_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10520550346157222"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.overall_purity(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': u'Bayer objects',\n",
       "  'cluster': 126,\n",
       "  'purity': 0.9056603773584906,\n",
       "  'size': 53},\n",
       " {'category': u'Stochastic processes',\n",
       "  'cluster': 157,\n",
       "  'purity': 0.8,\n",
       "  'size': 10}]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate.high_purity_clusters(res, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05750327134184522"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.adjusted_mutual_info_score(title_cats_code, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 10\n",
      "\n",
      "Girsanov theorem (cats: Stochastic processes, Probability theorems) F_t E E_P Ω X_t X_s W_t λ μ W_s σ Z_s Z_t F Y_t Y_s Q P T W Y X d l s r t X_0\n",
      "Stochastic differential equation (cats: Differential equations, Stochastic processes, Stochastic calculus, Stochastic differential equations) C f_i g_i Z X_t X_u μ η_m σ B E D R T x_i d g k j m l n s u t X_0 y x B_t\n",
      "Itō calculus (cats: Definitions of mathematical integration, Stochastic calculus) ξ_j ξ_k x_l x_m M C Y_0 F_t X_T h_k M_t t_i H_s p Ω σ_s X_t δ H_n μ X_s σ B E y F H J Y_t Y_s K x_k P α_s x_j X M_0 l c t_1 d f j f_i n π_n μ_s s t X_0 t_2 B_s B_t\n",
      "Quadratic variation (cats: Stochastic processes) Y_0 Δ V_t t_k C_p Ω σ_s X_v X_t X_u X_s μ_s Y_s σ E F H Y_t M c_p X d P k m l n p s u t X_0 v B_s\n",
      "Bessel process (cats: Stochastic processes) Z_t d n X_t t W_t\n",
      "Novikov's condition (cats: Stochastic processes, Martingale theory) E d F Ω s l t F_t P X_t X_s X W_t W_s T\n",
      "Semimartingale (cats: Stochastic processes, Martingale theory) Δ σ_s d H X_T s X_t t X_0 X b_s W_s M_t\n",
      "Tanaka equation (cats: Equations, Stochastic differential equations) B d m l p X_t t sgn x B_t X_s\n",
      "Filtering problem (stochastic processes) (cats: Control theory, Stochastic processes, Signal processing, Estimation theory, Stochastic differential equations) P_F C E H_t Σ H_s Ω G_t γ X_t W_t σ Z_t F K Y_t L P R Y X Z c b d n s t x B_t\n",
      "Dudley's theorem (cats: Stochastic processes, Entropy, Probability theorems) d_X E d X_s X_t N s ε t T\n",
      "\n",
      "common terms: (X_t d t)\n",
      "top categories: [(u'Stochastic processes', 8), (u'Stochastic differential equations', 3), (u'Martingale theory', 2), (u'Stochastic calculus', 2), (u'Probability theorems', 2)]\n",
      "purity: 0.800\n",
      "relations:\n",
      "    B: Brownian motion, Wiener process, proof\n",
      "    B_t: variance Var\n",
      "    C: constants\n",
      "    D: constants\n",
      "    E: conditional expectation operator, martingales\n",
      "    F: conditional expectation operator, filtration\n",
      "    F_t: information\n",
      "    G_t: observations\n",
      "    H: linearity, adapted, predictable process\n",
      "    H_t: observations\n",
      "    K: linear subspace\n",
      "    L: orthogonal projection\n",
      "    M: local martingale\n",
      "    M_0: deterministic calculus\n",
      "    P: partition, filtration, density transformation\n",
      "    Q: measure\n",
      "    R: Euclidean space, observations\n",
      "    T: pseudometric\n",
      "    W: Brownian motion\n",
      "    W_t: Brownian motion\n",
      "    X: process, quadratic variation, filtration, components\n",
      "    X_0: process\n",
      "    X_t: ΔX_t, quadratic variation, sup_s, stochastic process, with probability one\n",
      "    Y: local martingale\n",
      "    Y_t: system, local martingale\n",
      "    Z: filtration, linear subspace\n",
      "    Z_t: observations\n",
      "    b: Brownian motion\n",
      "    c: constants, initial condition X_0\n",
      "    d_X: pseudometric\n",
      "    f: differentiable function\n",
      "    f_i: unknowns\n",
      "    g_i: constants\n",
      "    l: Euclidean space\n",
      "    n: drift field, Euclidean space, real parameter\n",
      "    p: real number\n",
      "    predictable: finite variation process\n",
      "    r: free rate\n",
      "    s: Itō processe, predictable processe, stochastic processe\n",
      "    sgn: unconventional value\n",
      "    simple: processes\n",
      "    t: t-continuous solution, time index, quadratic variation, time\n",
      "    x_k: Itōs lemma\n",
      "    Δ: jumps\n",
      "    Σ: probability space\n",
      "    Ω: random variable\n",
      "    ε: radius\n",
      "    η_m: physics formulation\n",
      "    μ: expectation, assets drift\n",
      "    ξ_j: white noise\n",
      "    π_n: sequence\n",
      "    σ: drift field, drift coefficient, volatility\n"
     ]
    }
   ],
   "source": [
    "evaluate.print_cluster(res, 157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
