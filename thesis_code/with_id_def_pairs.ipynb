{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def id_counter(id_list):\n",
    "    cnt = Counter()\n",
    "    for el in id_list:\n",
    "        cnt[el[u'element']] = el[u'count']\n",
    "    return cnt\n",
    "\n",
    "def_black_list = { 'unit', 'units', 'value', 'values', 'axis', 'axes', 'factor', 'factors', 'line', 'lines',\n",
    "                 'point', 'points', 'number', 'numbers', 'variable', 'variables', 'respect', 'case', 'cases',\n",
    "                 'vector', 'vectors', 'element', 'elements', 'example', \n",
    "                 'integer', 'integers', 'term', 'terms', 'parameter', 'parameters', 'coefficient', 'coefficients',\n",
    "                 'formula', 'times', 'product', 'matrices', 'expression', 'complex', 'real', 'zeros', 'bits',\n",
    "                 'sign',\n",
    "                 'if and only if',\n",
    "                 'alpha', 'beta', 'gamma', 'delta', 'epsilon', 'zeta', 'eta', 'theta', 'iota', 'kappa', 'lambda', \n",
    "                 'mu', 'nu', 'xi', 'omicron', 'pi', 'rho', 'sigma', 'tau', 'upsilon', 'phi', 'chi', 'psi', 'omega'}\n",
    "\n",
    "def valid_def(definition):\n",
    "    if len(definition) <= 3:\n",
    "        return False\n",
    "\n",
    "    return definition.lower() not in def_black_list\n",
    "\n",
    "def rel_to_dict(rels):\n",
    "    res = defaultdict(list)\n",
    "    for r in rels:\n",
    "        if not valid_def(r['definition']):\n",
    "            continue\n",
    "        res[r['identifier']].append((r['definition'], r['score']))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "doc_categories = defaultdict(set)\n",
    "category_docs = defaultdict(set)\n",
    "\n",
    "for line in file('C:/tmp/mlp/category_info_refined.txt'):\n",
    "    title, cat = line.strip().split('\\t')\n",
    "    title = title.decode('utf-8')\n",
    "    cat = cat.decode('utf-8')\n",
    "\n",
    "    # let's also remove all documents from \"OTHER\" category\n",
    "    if cat == u'OTHER':\n",
    "        continue\n",
    "\n",
    "    doc_categories[title].add(cat) \n",
    "    category_docs[cat].add(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 7501\n",
      "22512\n"
     ]
    }
   ],
   "source": [
    "root = 'C:/tmp/mlp/mlp-output/'\n",
    "\n",
    "docs = []\n",
    "titles = []\n",
    "ids = []\n",
    "rels = []\n",
    "\n",
    "empty = 0\n",
    "small = 0\n",
    "uncategorized = 0\n",
    "\n",
    "for f in os.listdir(root): \n",
    "    for line in file(root + f):\n",
    "        doc = json.loads(line)\n",
    "\n",
    "        title = doc['title']        \n",
    "        if title not in doc_categories:\n",
    "            uncategorized = uncategorized + 1\n",
    "            continue\n",
    "\n",
    "        if '(disambiguation)' in title:\n",
    "            continue\n",
    "\n",
    "        id_bag = id_counter(doc['identifiers'])\n",
    "        if len(id_bag) <= 1:\n",
    "            if len(id_bag) == 0:\n",
    "                empty = empty + 1\n",
    "            else:\n",
    "                small = small + 1\n",
    "            continue\n",
    "\n",
    "        docs.append(doc)\n",
    "        titles.append(title)\n",
    "        ids.append(id_bag)\n",
    "\n",
    "        id_rels = rel_to_dict(doc['relations'])\n",
    "        rels.append(id_rels)\n",
    "\n",
    "print empty, small, uncategorized\n",
    "\n",
    "N_doc = len(ids)\n",
    "print N_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22512\n"
     ]
    }
   ],
   "source": [
    "title_idx = {title: idx for (idx, title) in enumerate(titles)}\n",
    "\n",
    "for doc, cats in doc_categories.items():\n",
    "    if doc in title_idx:\n",
    "        continue\n",
    "\n",
    "    for cat in cats: \n",
    "        category_docs[cat].remove(doc)\n",
    "    \n",
    "    del doc_categories[doc]\n",
    "\n",
    "print len(doc_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_categories_list = [doc_categories[doc] for doc in titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep a copy of identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = [id_counter(d['identifiers']) for d in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove least common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.736540511727078"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(doc_ids) for doc_ids in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in xrange(N_doc):\n",
    "    vals = rels[idx].items()\n",
    "    id_list = ids[idx]\n",
    "\n",
    "    for id, definitions in vals:\n",
    "        for definition, score in definitions:\n",
    "            for unigram in definition.lower().split():\n",
    "                stem = snowball_stemmer.stem(unigram)\n",
    "                key = u'%s_%s' % (id, stem)\n",
    "                id_list[key] = id_list[key] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148783\n",
      "115734\n",
      "33049\n"
     ]
    }
   ],
   "source": [
    "all_ids = Counter()\n",
    "\n",
    "for id_cnt in ids:\n",
    "    all_ids.update(id_cnt)\n",
    "\n",
    "print len(all_ids)\n",
    "\n",
    "infrequent = set()\n",
    "min_count = 2\n",
    "\n",
    "for (el, cnt) in all_ids.items():\n",
    "    if cnt <= min_count:\n",
    "        infrequent.add(el)\n",
    "\n",
    "print len(infrequent)\n",
    "\n",
    "for id_cnt in ids:\n",
    "    for id in (set(id_cnt) & infrequent):\n",
    "        del id_cnt[id]\n",
    "\n",
    "        \n",
    "all_ids = Counter()\n",
    "\n",
    "for id_cnt in ids:\n",
    "    all_ids.update(id_cnt)\n",
    "\n",
    "print len(all_ids)\n",
    "        \n",
    "del all_ids\n",
    "del infrequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.786202914001422"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(doc_ids) for doc_ids in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n t x m p d g k f R l y c r T π C P b S s N B E X F j\n"
     ]
    }
   ],
   "source": [
    "df = Counter()\n",
    "for cnt in ids:\n",
    "    df.update(list(cnt))\n",
    "\n",
    "top = 50\n",
    "mc = [id for (id, cnt) in df.most_common(top) if cnt > 3000]\n",
    "print ' '.join(mc)\n",
    "\n",
    "mc = set(mc)\n",
    "\n",
    "for id_cnt in ids:\n",
    "    for id in list(id_cnt):\n",
    "        if id in mc:\n",
    "            del id_cnt[id]\n",
    "\n",
    "del mc\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.980188343994314"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(doc_ids) for doc_ids in ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_idx = {}\n",
    "\n",
    "for (idx, id_list) in enumerate(ids):\n",
    "    for id in id_list: \n",
    "        if id in inv_idx:\n",
    "            inv_idx[id].append(idx)\n",
    "        else:\n",
    "            inv_idx[id] = [idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def docs_to_compare(doc_id):\n",
    "    res = set([])\n",
    "    id_list = ids[doc_id]\n",
    "    for id in id_list:\n",
    "        res.update(inv_idx[id])\n",
    "    if doc_id in res:\n",
    "        res.remove(doc_id)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4862.1899999999996"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(docs_to_compare(doc_id)) for doc_id in xrange(200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_matrix = 25\n",
    "k_graph = 15\n",
    "#sim_threshold = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_sets = [set(id_list) for id_list in ids]\n",
    "\n",
    "def calc_jaccard(set1, set2):\n",
    "    union = len(set1 | set2)\n",
    "    if not union: \n",
    "        return 0.0\n",
    "\n",
    "    inter = len(set1 & set2)\n",
    "    return inter * 1.0 / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1000\n",
      "iteration 2000\n",
      "iteration 3000\n",
      "iteration 4000\n",
      "iteration 5000\n",
      "iteration 6000\n",
      "iteration 7000\n",
      "iteration 8000\n",
      "iteration 9000\n",
      "iteration 10000\n",
      "iteration 11000\n",
      "iteration 12000\n",
      "iteration 13000\n",
      "iteration 14000\n",
      "iteration 15000\n",
      "iteration 16000\n",
      "iteration 17000\n",
      "iteration 18000\n",
      "iteration 19000\n",
      "iteration 20000\n",
      "iteration 21000\n",
      "iteration 22000\n",
      "done in 931.305s.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "shared_nn = []\n",
    "\n",
    "for i in xrange(N_doc):\n",
    "    if i % 1000 == 0:\n",
    "        print \"iteration %d\" % i\n",
    "\n",
    "    doc_ids = np.array(list(docs_to_compare(i)))\n",
    "    sim = np.zeros(len(doc_ids))\n",
    "\n",
    "    for (idx, j) in enumerate(doc_ids):\n",
    "        sim[idx] = calc_jaccard(ids_sets[i], ids_sets[j])\n",
    "    \n",
    "    sim_idx = sim.argsort()[-1:-k_matrix-1:-1]\n",
    "    doc_ids_to_add = doc_ids[sim_idx]\n",
    "\n",
    "    shared_nn.append(set(doc_ids_to_add[0:k_graph]))\n",
    "\n",
    "print \"done in %0.3fs.\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import snn_dbscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to look for best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cluster_evaluation\n",
    "import snn_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(cluster_evaluation)\n",
    "evaluate = cluster_evaluation.Evaluator(doc_titles=titles, doc_ids=ids, \n",
    "                                        doc_ids_definitions=rels, doc_categories=doc_categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22512"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity for eps=3, min_pts=3 is 0.3325, number of clusters: 3694, number of >0.8 clusters: 53\n",
      "purity for eps=3, min_pts=4 is 0.3264, number of clusters: 3558, number of >0.8 clusters: 53\n",
      "purity for eps=3, min_pts=5 is 0.3214, number of clusters: 3427, number of >0.8 clusters: 54\n",
      "purity for eps=3, min_pts=6 is 0.3167, number of clusters: 3318, number of >0.8 clusters: 47\n",
      "purity for eps=3, min_pts=7 is 0.3126, number of clusters: 3217, number of >0.8 clusters: 45\n",
      "purity for eps=3, min_pts=8 is 0.3080, number of clusters: 3131, number of >0.8 clusters: 41\n",
      "purity for eps=4, min_pts=3 is 0.3343, number of clusters: 4014, number of >0.8 clusters: 50\n",
      "purity for eps=4, min_pts=4 is 0.3189, number of clusters: 3668, number of >0.8 clusters: 49\n",
      "purity for eps=4, min_pts=5 is 0.3095, number of clusters: 3443, number of >0.8 clusters: 47\n",
      "purity for eps=4, min_pts=6 is 0.3016, number of clusters: 3265, number of >0.8 clusters: 42\n",
      "purity for eps=4, min_pts=7 is 0.2935, number of clusters: 3111, number of >0.8 clusters: 37\n",
      "purity for eps=4, min_pts=8 is 0.2868, number of clusters: 2979, number of >0.8 clusters: 39\n"
     ]
    }
   ],
   "source": [
    "eps_list = [3, 4]\n",
    "min_pts_list = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "hyperparam_purity = {}\n",
    "hyperparam_res = {}\n",
    "\n",
    "for eps in eps_list:\n",
    "    for min_pts in min_pts_list:\n",
    "        res = np.array(snn_dbscan.dbscan(shared_nn, eps=eps, min_pts=min_pts))\n",
    "        res[res == 'noise'] = 0\n",
    "        res = res.astype(int)\n",
    "\n",
    "        hyperparam_res[(eps, min_pts)] = res\n",
    "        cluster_purity = evaluate.overall_purity(res)\n",
    "        hyperparam_purity[(eps, min_pts)] = cluster_purity\n",
    "\n",
    "        no_clusters = len(np.unique(res))\n",
    "        no_pure_clusters = len(evaluate.high_purity_clusters(res, threshold=0.8))\n",
    "\n",
    "        print 'purity for eps=%d, min_pts=%d is %0.4f, number of clusters: %d, number of >0.8 clusters: %d' % \\\n",
    "              (eps, min_pts, cluster_purity, no_clusters, no_pure_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for untruncated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity for eps=3, min_pts=3 is 0.4807, number of clusters: 7028, number of >0.8 clusters: 79\n",
      "purity for eps=3, min_pts=4 is 0.4665, number of clusters: 6687, number of >0.8 clusters: 82\n",
      "purity for eps=3, min_pts=5 is 0.4541, number of clusters: 6394, number of >0.8 clusters: 78\n",
      "purity for eps=3, min_pts=6 is 0.4412, number of clusters: 6117, number of >0.8 clusters: 82\n",
      "purity for eps=3, min_pts=7 is 0.4315, number of clusters: 5909, number of >0.8 clusters: 80\n",
      "purity for eps=4, min_pts=3 is 0.4446, number of clusters: 6497, number of >0.8 clusters: 61\n",
      "purity for eps=4, min_pts=4 is 0.4148, number of clusters: 5820, number of >0.8 clusters: 73\n",
      "purity for eps=4, min_pts=5 is 0.3888, number of clusters: 5276, number of >0.8 clusters: 72\n",
      "purity for eps=4, min_pts=6 is 0.3703, number of clusters: 4844, number of >0.8 clusters: 66\n",
      "purity for eps=4, min_pts=7 is 0.3530, number of clusters: 4491, number of >0.8 clusters: 58\n",
      "purity for eps=5, min_pts=3 is 0.3678, number of clusters: 4999, number of >0.8 clusters: 60\n",
      "purity for eps=5, min_pts=4 is 0.3352, number of clusters: 4297, number of >0.8 clusters: 62\n",
      "purity for eps=5, min_pts=5 is 0.3114, number of clusters: 3818, number of >0.8 clusters: 60\n",
      "purity for eps=5, min_pts=6 is 0.2929, number of clusters: 3420, number of >0.8 clusters: 50\n",
      "purity for eps=5, min_pts=7 is 0.2736, number of clusters: 3088, number of >0.8 clusters: 39\n",
      "purity for eps=6, min_pts=3 is 0.2954, number of clusters: 3589, number of >0.8 clusters: 47\n",
      "purity for eps=6, min_pts=4 is 0.2655, number of clusters: 2991, number of >0.8 clusters: 50\n",
      "purity for eps=6, min_pts=5 is 0.2434, number of clusters: 2578, number of >0.8 clusters: 48\n",
      "purity for eps=6, min_pts=6 is 0.2271, number of clusters: 2240, number of >0.8 clusters: 40\n",
      "purity for eps=6, min_pts=7 is 0.2128, number of clusters: 1986, number of >0.8 clusters: 31\n",
      "purity for eps=7, min_pts=3 is 0.2382, number of clusters: 2500, number of >0.8 clusters: 43\n",
      "purity for eps=7, min_pts=4 is 0.2125, number of clusters: 2024, number of >0.8 clusters: 41\n",
      "purity for eps=7, min_pts=5 is 0.1937, number of clusters: 1687, number of >0.8 clusters: 42\n",
      "purity for eps=7, min_pts=6 is 0.1783, number of clusters: 1413, number of >0.8 clusters: 31\n",
      "purity for eps=7, min_pts=7 is 0.1672, number of clusters: 1234, number of >0.8 clusters: 26\n",
      "purity for eps=8, min_pts=3 is 0.1939, number of clusters: 1722, number of >0.8 clusters: 29\n",
      "purity for eps=8, min_pts=4 is 0.1707, number of clusters: 1308, number of >0.8 clusters: 26\n",
      "purity for eps=8, min_pts=5 is 0.1550, number of clusters: 1044, number of >0.8 clusters: 25\n",
      "purity for eps=8, min_pts=6 is 0.1445, number of clusters: 867, number of >0.8 clusters: 19\n",
      "purity for eps=8, min_pts=7 is 0.1381, number of clusters: 757, number of >0.8 clusters: 17\n",
      "purity for eps=9, min_pts=3 is 0.1581, number of clusters: 1129, number of >0.8 clusters: 21\n",
      "purity for eps=9, min_pts=4 is 0.1437, number of clusters: 880, number of >0.8 clusters: 20\n",
      "purity for eps=9, min_pts=5 is 0.1341, number of clusters: 693, number of >0.8 clusters: 18\n",
      "purity for eps=9, min_pts=6 is 0.1273, number of clusters: 595, number of >0.8 clusters: 12\n",
      "purity for eps=9, min_pts=7 is 0.1215, number of clusters: 501, number of >0.8 clusters: 11\n",
      "purity for eps=10, min_pts=3 is 0.1389, number of clusters: 811, number of >0.8 clusters: 14\n",
      "purity for eps=10, min_pts=4 is 0.1286, number of clusters: 624, number of >0.8 clusters: 13\n",
      "purity for eps=10, min_pts=5 is 0.1217, number of clusters: 499, number of >0.8 clusters: 13\n",
      "purity for eps=10, min_pts=6 is 0.1162, number of clusters: 410, number of >0.8 clusters: 9\n",
      "purity for eps=10, min_pts=7 is 0.1128, number of clusters: 361, number of >0.8 clusters: 8\n"
     ]
    }
   ],
   "source": [
    "eps_list = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "min_pts_list = [3, 4, 5, 6, 7]\n",
    "\n",
    "hyperparam_purity = {}\n",
    "hyperparam_res = {}\n",
    "\n",
    "for eps in eps_list:\n",
    "    for min_pts in min_pts_list:\n",
    "        res = np.array(snn_dbscan.dbscan(jaccard_ssn_15, eps=eps, min_pts=min_pts))\n",
    "        res[res == 'noise'] = 0\n",
    "        res = res.astype(int)\n",
    "\n",
    "        hyperparam_res[(eps, min_pts)] = res\n",
    "        cluster_purity = evaluate.overall_purity(res)\n",
    "        hyperparam_purity[(eps, min_pts)] = cluster_purity\n",
    "\n",
    "        no_clusters = len(np.unique(res))\n",
    "        no_pure_clusters = len(evaluate.high_purity_clusters(res, threshold=0.8))\n",
    "\n",
    "        print 'purity for eps=%d, min_pts=%d is %0.4f, number of clusters: %d, number of >0.8 clusters: %d' % \\\n",
    "              (eps, min_pts, cluster_purity, no_clusters, no_pure_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall purity 0.4665\n",
      "number of high purity clusters of size at least 5 is 82\n",
      "\n",
      "- Group theory (id=6038) size=21, purity=0.9524\n",
      "- Propositional calculus (id=6705) size=21, purity=0.8095\n",
      "- Astronomical catalogues (id=5951) size=20, purity=1.0000\n",
      "- National Basketball Association seasons (id=3121) size=13, purity=0.9231\n",
      "- Thermodynamics (id=5793) size=11, purity=0.9091\n",
      "- Enzymes (id=58) size=10, purity=0.9000\n",
      "- Linear algebra (id=6095) size=10, purity=0.8000\n",
      "- Statistics (id=6867) size=10, purity=0.8000\n",
      "- Group theory (id=6292) size=9, purity=1.0000\n",
      "- Lie groups (id=531) size=8, purity=0.8750\n",
      "- Differential geometry (id=1709) size=8, purity=0.8750\n",
      "- Topology (id=3509) size=8, purity=0.8750\n",
      "- Graph theory (id=5042) size=8, purity=1.0000\n",
      "- Thermodynamics (id=6003) size=8, purity=1.0000\n",
      "- Mathematical optimization (id=150) size=7, purity=1.0000\n",
      "- Quantum mechanics (id=413) size=7, purity=0.8571\n",
      "- Combinatorics (id=1663) size=7, purity=0.8571\n",
      "- Materials science (id=3661) size=7, purity=0.8571\n",
      "- Graph theory (id=5948) size=7, purity=0.8571\n",
      "- Special functions (id=6569) size=7, purity=0.8571\n",
      "- Quantum mechanics (id=757) size=6, purity=0.8333\n",
      "- Electromagnetism (id=1582) size=6, purity=1.0000\n",
      "- Quantum field theory (id=2012) size=6, purity=0.8333\n",
      "- Differential topology (id=2387) size=6, purity=0.8333\n",
      "- Quantum field theory (id=2486) size=6, purity=0.8333\n",
      "- Computational neuroscience (id=2634) size=6, purity=0.8333\n",
      "- Statistics (id=4746) size=6, purity=0.8333\n",
      "- Differential equations (id=4851) size=6, purity=1.0000\n",
      "- Statistics (id=5466) size=6, purity=1.0000\n",
      "- Quantum mechanics (id=5655) size=6, purity=1.0000\n",
      "- Mechanics (id=5845) size=6, purity=0.8333\n",
      "- Physical quantities (id=5846) size=6, purity=1.0000\n",
      "- Physics (id=6172) size=6, purity=1.0000\n",
      "- Probability distributions (id=6471) size=6, purity=1.0000\n",
      "- Abstract algebra (id=6993) size=6, purity=1.0000\n",
      "- Astronomical sub-disciplines (id=158) size=5, purity=0.8000\n",
      "- Metalogic (id=194) size=5, purity=0.8000\n",
      "- Abstract algebra (id=211) size=5, purity=1.0000\n",
      "- String (computer science) (id=472) size=5, purity=0.8000\n",
      "- Biostatistics (id=926) size=5, purity=0.8000\n",
      "- Stochastic processes (id=942) size=5, purity=0.8000\n",
      "- Algebraic topology (id=1258) size=5, purity=1.0000\n",
      "- Physical cosmology (id=1351) size=5, purity=1.0000\n",
      "- Cryptography (id=1505) size=5, purity=1.0000\n",
      "- Telecommunication theory (id=1506) size=5, purity=0.8000\n",
      "- Linear algebra (id=1566) size=5, purity=0.8000\n",
      "- Banach algebras (id=1816) size=5, purity=0.8000\n",
      "- Abstract algebra (id=1923) size=5, purity=1.0000\n",
      "- Spectroscopy (id=1933) size=5, purity=1.0000\n",
      "- Quantum mechanics (id=2064) size=5, purity=1.0000\n",
      "- Statistics (id=2274) size=5, purity=1.0000\n",
      "- Plasma physics (id=2364) size=5, purity=1.0000\n",
      "- Statistical theory (id=2456) size=5, purity=1.0000\n",
      "- Quantum mechanics (id=3567) size=5, purity=1.0000\n",
      "- Group theory (id=3644) size=5, purity=1.0000\n",
      "- Differential topology (id=3899) size=5, purity=1.0000\n",
      "- Coding theory (id=3962) size=5, purity=0.8000\n",
      "- Group theory (id=4083) size=5, purity=0.8000\n",
      "- Differential equations (id=4403) size=5, purity=1.0000\n",
      "- Stochastic processes (id=4512) size=5, purity=0.8000\n",
      "- Theories of gravitation (id=4921) size=5, purity=1.0000\n",
      "- Physics (id=4992) size=5, purity=0.8000\n",
      "- Manifolds (id=5081) size=5, purity=0.8000\n",
      "- Representation theory (id=5119) size=5, purity=1.0000\n",
      "- Fluid dynamics (id=5446) size=5, purity=0.8000\n",
      "- Numerical linear algebra (id=5449) size=5, purity=0.8000\n",
      "- Complex analysis (id=5538) size=5, purity=0.8000\n",
      "- Differential geometry (id=5830) size=5, purity=1.0000\n",
      "- Group theory (id=6017) size=5, purity=0.8000\n",
      "- Surgery theory (id=6105) size=5, purity=0.8000\n",
      "- Linear algebra (id=6127) size=5, purity=1.0000\n",
      "- Mathematical analysis (id=6159) size=5, purity=0.8000\n",
      "- Probability theory (id=6203) size=5, purity=1.0000\n",
      "- Physics (id=6315) size=5, purity=0.8000\n",
      "- Numerical analysis (id=6374) size=5, purity=0.8000\n",
      "- Search algorithms (id=6468) size=5, purity=0.8000\n",
      "- Materials science (id=6743) size=5, purity=0.8000\n",
      "- Special relativity (id=6756) size=5, purity=0.8000\n",
      "- Polygons (id=6789) size=5, purity=1.0000\n",
      "- Waves (id=6850) size=5, purity=0.8000\n",
      "- Mathematical analysis (id=6898) size=5, purity=0.8000\n",
      "- Thermodynamics (id=7062) size=5, purity=0.8000\n"
     ]
    }
   ],
   "source": [
    "evaluate.report_overall(hyperparam_res[(3, 4)], purity_threshold=0.8, sort_by='size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 5\n",
      "\n",
      "- Minor (linear algebra) (categories: Linear algebra, Matrix theory, Multilinear algebra, Determinants) k_matrix k_size C_11 p_matrix n C_21 C_22 M_23_c_23 n_matrix M_23_cofactor M_23 k_determinant M_23_entry C m_matrix K K_subsets T n_columns k_rows m_rows k j m C_12 j_cofactor p k_columns n_rows\n",
      "- Centering matrix (categories: Statistics, Linear algebra, Statistical data types, Mathematical objects, Linear operators, ...) p_n X_sample m v_column-vector C_n O_size v_size X_data v_projection n_matrix C_1 n_identity C_3 C_2 n_size X_matrix μ C_n_semi-definite C n_ones O_matrix O S X_m-by-n C_n_property X p_2 p_1 X_multiplication O_n-by-n m_rows k C_m n p v n_column-vector v_components C_n_positive\n",
      "- Kronecker product (categories: Linear algebra, Matrix theory) BD D_size B_transformations AC_matrix P_matrices m_matrix AC X_basis AXB BD_matrix AXB_instance p_matrix Q_permutation k_scalar r_B_kronecker B_12 r_A r_B B_11 B_nq r_A_nonzero B_⊗ p_q Q_matrices n_matrix B_product C_1 D_such C_3 C_2 D_3 B_linear B_block P_permutation b_22 b_21 C B D B_mp D_2 H BD_products D_1 AC_products X_matrix Q P B_general T X k_identity k_matrix B_22 B_21 B_× λ_i B_tensor μ_j B_a k j m n p B_matrix H_Tot b_12 b_11 B_kronecker\n",
      "- Generalized singular value decomposition (categories: Algebra, Linear algebra, Operator theory, Matrix decompositions, Singular value decomposition) U_matrix Σ_2_blocks W_u_constraints n_complex Σ β_i n_matrix α r W_v_constraints W_u W_v U_identity C B β F M α_i Σ_1 R U T V X Q M_matrix σ_i k m n p B_matrix Σ_2 M_complex\n",
      "- Symmetric matrix (categories: Linear algebra, Mathematical objects, Linear operators, Matrix theory, Matrices) x_form T_triangular Q_matrix x_n j_indices Sym_n_space λ_2_eigenvalues x_orthogonality Λ Mat_n_space R_product R_inner Sym_n L_transpose X_square Mat_n q_quadratic n_matrix n_a q_form T_matrix Q_unitary λ_1 P_matrix λ_2 P_permutation Q_orthogonal X_y L_matrix R_standard D D_diagonal X_commute L X_matrix Q P R T L_pivot x_1 D_matrix X L_lower-triangular R_basis λ_i T_tridiagonal y_eigenvectors R_form λ_1_eigenvalues x_eigenvectors j m n q p R_orthonormal Skew_n_space Skew_n y x R_quadratic T_a. T_denote\n",
      "\n",
      "common terms: (p m n_matrix n)\n",
      "top categories: [(u'Linear algebra', 5), (u'Matrix theory', 4), (u'Mathematical objects', 2), (u'Linear operators', 2), (u'Matrices', 2)]\n",
      "purity: 1.000\n",
      "relations:\n",
      "    AC: (matrix products: 8.99)\n",
      "    AXB: (instance: 8.35)\n",
      "    B: (matrix: 10.79), (linear transformations: 8.45), (mp × nq block matrix: 7.94), (Kronecker: 7.74), (tensor product: 7.69), (general A ⊗: 7.62)\n",
      "    BD: (matrix products: 8.13)\n",
      "    C_n: (property: 8.64), (positive semi-definite: 7.80)\n",
      "    D: (such size: 7.51), (diagonal matrix: 6.51)\n",
      "    K: (subsets: 7.52)\n",
      "    L: (lower-triangular matrix: 9.21), (transpose: 8.35), (pivot: 8.02)\n",
      "    M: (complex matrix: 8.81)\n",
      "    M_23: (entry: 8.31), (cofactor C_23: 8.13)\n",
      "    Mat_n: (space: 7.98)\n",
      "    O: (n-by-n matrix: 8.35), (size: 7.98)\n",
      "    P: (permutation matrices: 8.99), (permutation matrix: 6.61)\n",
      "    Q: (permutation matrices: 8.13), (orthogonal matrix: 7.84), (unitary matrix: 6.64)\n",
      "    R: (standard: 7.77), (inner product: 7.25), (orthonormal basis: 7.19), (quadratic form: 7.07)\n",
      "    Skew_n: (space: 8.48)\n",
      "    Sym_n: (space: 7.98)\n",
      "    T: (matrix A.: 8.13), (triangular matrix: 7.95), (Denote: 7.51), (tridiagonal matrix: 7.22)\n",
      "    U: (Identity Matrix: 7.80)\n",
      "    W_u: (constraints: 8.86)\n",
      "    W_v: (constraints: 7.74)\n",
      "    X: (matrix: 10.89), (m-by-n matrix: 8.99), (data sample: 8.66), (Y commute: 8.24), (square matrix: 7.73), (multiplication: 7.33), (basis: 7.06)\n",
      "    j: (cofactor: 7.35), (indices: 5.95)\n",
      "    k: (matrix: 13.36), (identity matrix: 7.81), (determinant: 7.70), (scalar: 7.33), (rows: 7.18), (columns: 6.50), (size: 5.01)\n",
      "    m: (rows: 12.30), (matrix: 9.89)\n",
      "    n: (matrix: 19.65), (size: 13.70), (column-vector: 8.38), (complex matrix: 7.53), (ones: 7.43), (matrix A: 6.81), (identity matrix: 6.20), (rows: 5.75), (columns: 5.53)\n",
      "    p: (q matrix: 14.07), (matrix: 14.05)\n",
      "    q: (quadratic form: 7.29), (form: 7.04)\n",
      "    r_A: (nonzero: 9.10)\n",
      "    r_B: (Kronecker: 8.13)\n",
      "    v: (column-vector: 8.86), (size: 7.99), (projection: 7.69), (components: 6.72)\n",
      "    x: (orthogonality: 8.13), (eigenvectors: 6.78), (form: 4.64)\n",
      "    y: (eigenvectors: 8.20)\n",
      "    Σ_2: (blocks: 8.86)\n",
      "    λ_1: (eigenvalues: 7.44)\n",
      "    λ_2: (eigenvalues: 6.74)\n"
     ]
    }
   ],
   "source": [
    "evaluate.print_cluster(hyperparam_res[(3, 4)], 6127, collection_weighting=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall purity 0.2294\n",
      "number of high purity clusters of size at least 5 is 83\n",
      "\n",
      "- Abstract algebra (id=79) size=45, purity=0.8444\n",
      "- Coding theory (id=135) size=31, purity=0.9677\n",
      "- Astronomical catalogues (id=1023) size=24, purity=1.0000\n",
      "- Group theory (id=1406) size=24, purity=0.9167\n",
      "- Solid mechanics (id=82) size=21, purity=0.8571\n",
      "- Category theory (id=140) size=19, purity=0.9474\n",
      "- Complex analysis (id=108) size=18, purity=1.0000\n",
      "- Functional analysis (id=109) size=17, purity=0.8235\n",
      "- Numerical analysis (id=20) size=16, purity=0.8750\n",
      "- Probability theory (id=301) size=16, purity=0.8750\n",
      "- Cartographic projections (id=531) size=16, purity=0.8750\n",
      "- Chemical elements (id=496) size=15, purity=0.9333\n",
      "- Fluid dynamics (id=519) size=15, purity=0.8000\n",
      "- National Basketball Association seasons (id=644) size=15, purity=0.8000\n",
      "- Mechanics (id=363) size=14, purity=0.9286\n",
      "- Physical cosmology (id=454) size=14, purity=0.8571\n",
      "- Cartography (id=226) size=12, purity=0.9167\n",
      "- Radio frequency propagation (id=260) size=12, purity=1.0000\n",
      "- Theoretical physics (id=279) size=12, purity=0.8333\n",
      "- Stochastic processes (id=388) size=12, purity=0.8333\n",
      "- General relativity (id=521) size=12, purity=0.8333\n",
      "- Polynomials (id=1248) size=12, purity=0.9167\n",
      "- Topology (id=22) size=11, purity=0.8182\n",
      "- Enzymes (id=29) size=11, purity=0.8182\n",
      "- Algebraic number theory (id=293) size=11, purity=0.9091\n",
      "- Quantum mechanics (id=366) size=11, purity=0.9091\n",
      "- Dimensionless numbers (id=15) size=10, purity=1.0000\n",
      "- Quantum mechanics (id=278) size=10, purity=0.9000\n",
      "- Financial economics (id=302) size=10, purity=0.8000\n",
      "- Polynomials (id=726) size=10, purity=1.0000\n",
      "- Propositional calculus (id=926) size=10, purity=0.9000\n",
      "- Signal processing (id=80) size=9, purity=0.8889\n",
      "- Stochastic processes (id=265) size=9, purity=1.0000\n",
      "- Measure theory (id=12) size=8, purity=0.8750\n",
      "- Linear algebra (id=150) size=8, purity=0.8750\n",
      "- Constellations (id=553) size=8, purity=1.0000\n",
      "- Electromagnetism (id=639) size=8, purity=1.0000\n",
      "- Estimation theory (id=655) size=8, purity=1.0000\n",
      "- Fluid dynamics (id=938) size=8, purity=0.8750\n",
      "- Differential geometry (id=1013) size=8, purity=0.8750\n",
      "- Linear algebra (id=1470) size=8, purity=1.0000\n",
      "- Optics (id=1477) size=8, purity=1.0000\n",
      "- Set theory (id=621) size=7, purity=1.0000\n",
      "- Particle physics (id=951) size=7, purity=0.8571\n",
      "- Group theory (id=1205) size=7, purity=1.0000\n",
      "- Signal processing (id=1389) size=7, purity=0.8571\n",
      "- Group theory (id=1414) size=7, purity=0.8571\n",
      "- Short-rate models (id=55) size=6, purity=0.8333\n",
      "- Elementary shapes (id=593) size=6, purity=0.8333\n",
      "- Group theory (id=761) size=6, purity=1.0000\n",
      "- Matroid theory (id=846) size=6, purity=1.0000\n",
      "- Graph theory (id=921) size=6, purity=0.8333\n",
      "- Linear algebra (id=1060) size=6, purity=0.8333\n",
      "- Partial differential equations (id=1118) size=6, purity=0.8333\n",
      "- Thermodynamics (id=1467) size=6, purity=1.0000\n",
      "- Mathematical analysis (id=14) size=5, purity=0.8000\n",
      "- HR objects (id=155) size=5, purity=0.8000\n",
      "- Physics (id=314) size=5, purity=0.8000\n",
      "- Cryptography (id=372) size=5, purity=0.8000\n",
      "- Differential geometry (id=413) size=5, purity=1.0000\n",
      "- Fluid dynamics (id=416) size=5, purity=1.0000\n",
      "- Quantum mechanics (id=433) size=5, purity=1.0000\n",
      "- Modal logic (id=455) size=5, purity=1.0000\n",
      "- Abstract algebra (id=466) size=5, purity=0.8000\n",
      "- Dimensionless numbers (id=606) size=5, purity=0.8000\n",
      "- Physics (id=608) size=5, purity=0.8000\n",
      "- Quantum field theory (id=670) size=5, purity=1.0000\n",
      "- Fluid mechanics (id=714) size=5, purity=0.8000\n",
      "- Tensors (id=814) size=5, purity=0.8000\n",
      "- Operator algebras (id=845) size=5, purity=1.0000\n",
      "- Materials science (id=862) size=5, purity=0.8000\n",
      "- Gaming (id=989) size=5, purity=1.0000\n",
      "- Information theory (id=1012) size=5, purity=0.8000\n",
      "- Differential equations (id=1031) size=5, purity=1.0000\n",
      "- Differential topology (id=1078) size=5, purity=0.8000\n",
      "- Gases (id=1351) size=5, purity=1.0000\n",
      "- Descriptive set theory (id=1354) size=5, purity=0.8000\n",
      "- Stochastic processes (id=1384) size=5, purity=1.0000\n",
      "- Prime numbers (id=1393) size=5, purity=0.8000\n",
      "- Algebra (id=1408) size=5, purity=1.0000\n",
      "- Classical mechanics (id=1438) size=5, purity=1.0000\n",
      "- Electromagnetic radiation (id=1502) size=5, purity=1.0000\n",
      "- Quantum mechanics (id=1515) size=5, purity=0.8000\n"
     ]
    }
   ],
   "source": [
    "evaluate.report_overall(hyperparam_res[(6, 5)], purity_threshold=0.8, sort_by='size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  K-means and Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = [id_counter(d['identifiers']) for d in docs]\n",
    "\n",
    "for idx in xrange(N_doc):\n",
    "    vals = rels[idx].items()\n",
    "    id_list = ids[idx]\n",
    "\n",
    "    for id, definitions in vals:\n",
    "        for definition, score in definitions:\n",
    "            for unigram in definition.lower().split():\n",
    "                stem = snowball_stemmer.stem(unigram)\n",
    "                key = u'%s_%s' % (id, stem)\n",
    "                id_list[key] = id_list[key] + 1\n",
    "\n",
    "all_ids = Counter()\n",
    "\n",
    "for id_cnt in ids:\n",
    "    all_ids.update(id_cnt)\n",
    "\n",
    "infrequent = set()\n",
    "min_count = 5\n",
    "\n",
    "for (el, cnt) in all_ids.items():\n",
    "    if cnt <= min_count:\n",
    "        infrequent.add(el)\n",
    "\n",
    "for id_cnt in ids:\n",
    "    for id in (set(id_cnt) & infrequent):\n",
    "        del id_cnt[id]\n",
    "\n",
    "del all_ids\n",
    "del infrequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unwrap_counter(cnt):\n",
    "    res = []\n",
    "    for id, c in cnt.items():\n",
    "        res.extend([id] * c)\n",
    "    return res\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=unwrap_counter, use_idf=True)\n",
    "X = vectorizer.fit_transform(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22512x33049 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 512963 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't seem to give good results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purity for k=2000 is 0.1413 number of >0.8 clusters: 1\n",
      "purity for k=2100 is 0.1346 number of >0.8 clusters: 0\n",
      "purity for k=2200 is 0.1289 number of >0.8 clusters: 0\n",
      "purity for k=2300 is 0.1350 number of >0.8 clusters: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-64f77674f201>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mkm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'random'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mkm_hyperparam_res\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\anaconda\\2.0.1\\lib\\site-packages\\sklearn\\cluster\\k_means_.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1277\u001b[0m                 \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalidation_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m                 \u001b[0mcluster_centers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_center_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1279\u001b[1;33m                 distances=None, verbose=self.verbose)\n\u001b[0m\u001b[0;32m   1280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1281\u001b[0m             \u001b[1;31m# Keep only the best cluster centers across independent inits on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\anaconda\\2.0.1\\lib\\site-packages\\sklearn\\cluster\\k_means_.pyc\u001b[0m in \u001b[0;36m_mini_batch_step\u001b[1;34m(X, x_squared_norms, centers, counts, old_center_buffer, compute_squared_diff, distances, random_reassign, random_state, reassignment_ratio, verbose)\u001b[0m\n\u001b[0;32m    984\u001b[0m         return inertia, _k_means._mini_batch_update_csr(\n\u001b[0;32m    985\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnearest_center\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m             old_center_buffer, compute_squared_diff)\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m     \u001b[1;31m# dense variant in mostly numpy (not as memory efficient though)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "km_hyperparam_purity = {}\n",
    "km_hyperparam_res = {}\n",
    "\n",
    "ks = [k * 100 for k in xrange(20, 31)]\n",
    "\n",
    "for k in ks:\n",
    "    km = MiniBatchKMeans(n_clusters=k, init_size=k*3, n_init=10, init='random')\n",
    "    km.fit(X)\n",
    "\n",
    "    km_hyperparam_res[k] = km.labels_\n",
    "    cluster_purity = evaluate.overall_purity(km.labels_)\n",
    "    km_hyperparam_purity[k] = cluster_purity\n",
    "\n",
    "    no_pure_clusters = len(evaluate.high_purity_clusters(km.labels_, threshold=0.8))\n",
    "\n",
    "    print 'purity for k=%d is %0.4f number of >0.8 clusters: %d' % (k, cluster_purity, no_pure_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing LSA with 300 components...\n",
      "\n",
      "purity for n=300, k=2500 is 0.3221, number of >0.8 clusters: 49\n",
      "purity for n=300, k=2600 is 0.3210, number of >0.8 clusters: 29\n",
      "purity for n=300, k=2700 is 0.3231, number of >0.8 clusters: 37\n",
      "purity for n=300, k=2800 is 0.3306, number of >0.8 clusters: 39\n",
      "purity for n=300, k=2900 is 0.3363, number of >0.8 clusters: 41\n",
      "purity for n=300, k=3000 is 0.3366, number of >0.8 clusters: 38\n",
      "purity for n=300, k=3100 is 0.3454, number of >0.8 clusters: 43\n",
      "purity for n=300, k=3200 is 0.3505, number of >0.8 clusters: 53\n",
      "purity for n=300, k=3300 is 0.3551, number of >0.8 clusters: 55\n",
      "purity for n=300, k=3400 is 0.3576, number of >0.8 clusters: 48\n",
      "purity for n=300, k=3500 is 0.3652, number of >0.8 clusters: 49\n",
      "purity for n=300, k=3600 is 0.3628, number of >0.8 clusters: 53\n",
      "purity for n=300, k=3700 is 0.3744, number of >0.8 clusters: 54\n",
      "purity for n=300, k=3800 is 0.3674, number of >0.8 clusters: 43\n",
      "purity for n=300, k=3900 is 0.3810, number of >0.8 clusters: 56\n",
      "purity for n=300, k=4000 is 0.3869, number of >0.8 clusters: 67\n",
      "purity for n=300, k=4100 is 0.3829, number of >0.8 clusters: 55\n",
      "purity for n=300, k=4200 is 0.3838, number of >0.8 clusters: 56\n",
      "purity for n=300, k=4300 is 0.3906, number of >0.8 clusters: 60\n",
      "purity for n=300, k=4400 is 0.3949, number of >0.8 clusters: 50\n",
      "purity for n=300, k=4500 is 0.4008, number of >0.8 clusters: 61\n",
      "doing LSA with 400 components...\n",
      "\n",
      "purity for n=400, k=2500 is 0.3152, number of >0.8 clusters: 48\n",
      "purity for n=400, k=2600 is 0.3262, number of >0.8 clusters: 42\n",
      "purity for n=400, k=2700 is 0.3348, number of >0.8 clusters: 58\n",
      "purity for n=400, k=2800 is 0.3236, number of >0.8 clusters: 39\n",
      "purity for n=400, k=2900 is 0.3340, number of >0.8 clusters: 36\n",
      "purity for n=400, k=3000 is 0.3361, number of >0.8 clusters: 39\n",
      "purity for n=400, k=3100 is 0.3450, number of >0.8 clusters: 39\n",
      "purity for n=400, k=3200 is 0.3452, number of >0.8 clusters: 48\n",
      "purity for n=400, k=3300 is 0.3510, number of >0.8 clusters: 42\n",
      "purity for n=400, k=3400 is 0.3567, number of >0.8 clusters: 54\n",
      "purity for n=400, k=3500 is 0.3604, number of >0.8 clusters: 48\n",
      "purity for n=400, k=3600 is 0.3706, number of >0.8 clusters: 60\n",
      "purity for n=400, k=3700 is 0.3730, number of >0.8 clusters: 43\n",
      "purity for n=400, k=3800 is 0.3703, number of >0.8 clusters: 51\n",
      "purity for n=400, k=3900 is 0.3785, number of >0.8 clusters: 57\n",
      "purity for n=400, k=4000 is 0.3863, number of >0.8 clusters: 64\n",
      "purity for n=400, k=4100 is 0.3826, number of >0.8 clusters: 57\n",
      "purity for n=400, k=4200 is 0.3921, number of >0.8 clusters: 57\n",
      "purity for n=400, k=4300 is 0.4019, number of >0.8 clusters: 63\n",
      "purity for n=400, k=4400 is 0.4017, number of >0.8 clusters: 50\n",
      "purity for n=400, k=4500 is 0.4011, number of >0.8 clusters: 58\n",
      "doing LSA with 500 components...\n",
      "\n",
      "purity for n=500, k=2500 is 0.3165, number of >0.8 clusters: 35\n",
      "purity for n=500, k=2600 is 0.3296, number of >0.8 clusters: 49\n",
      "purity for n=500, k=2700 is 0.3274, number of >0.8 clusters: 33\n",
      "purity for n=500, k=2800 is 0.3277, number of >0.8 clusters: 52\n",
      "purity for n=500, k=2900 is 0.3402, number of >0.8 clusters: 45\n",
      "purity for n=500, k=3000 is 0.3350, number of >0.8 clusters: 56\n",
      "purity for n=500, k=3100 is 0.3496, number of >0.8 clusters: 49\n",
      "purity for n=500, k=3200 is 0.3531, number of >0.8 clusters: 51\n",
      "purity for n=500, k=3300 is 0.3578, number of >0.8 clusters: 58\n",
      "purity for n=500, k=3400 is 0.3552, number of >0.8 clusters: 50\n",
      "purity for n=500, k=3500 is 0.3637, number of >0.8 clusters: 47\n",
      "purity for n=500, k=3600 is 0.3626, number of >0.8 clusters: 52\n",
      "purity for n=500, k=3700 is 0.3663, number of >0.8 clusters: 46\n",
      "purity for n=500, k=3800 is 0.3730, number of >0.8 clusters: 55\n",
      "purity for n=500, k=3900 is 0.3761, number of >0.8 clusters: 51\n",
      "purity for n=500, k=4000 is 0.3877, number of >0.8 clusters: 68\n",
      "purity for n=500, k=4100 is 0.3829, number of >0.8 clusters: 52\n",
      "purity for n=500, k=4200 is 0.3947, number of >0.8 clusters: 75\n",
      "purity for n=500, k=4300 is 0.3972, number of >0.8 clusters: 76\n",
      "purity for n=500, k=4400 is 0.3980, number of >0.8 clusters: 66\n",
      "purity for n=500, k=4500 is 0.3978, number of >0.8 clusters: 55\n",
      "doing LSA with 600 components...\n",
      "\n",
      "purity for n=600, k=2500 is 0.3113, number of >0.8 clusters: 33\n",
      "purity for n=600, k=2600 is 0.3246, number of >0.8 clusters: 46\n",
      "purity for n=600, k=2700 is 0.3331, number of >0.8 clusters: 49\n",
      "purity for n=600, k=2800 is 0.3286, number of >0.8 clusters: 44\n",
      "purity for n=600, k=2900 is 0.3343, number of >0.8 clusters: 34\n",
      "purity for n=600, k=3000 is 0.3381, number of >0.8 clusters: 50\n",
      "purity for n=600, k=3100 is 0.3432, number of >0.8 clusters: 63\n",
      "purity for n=600, k=3200 is 0.3546, number of >0.8 clusters: 61\n",
      "purity for n=600, k=3300 is 0.3502, number of >0.8 clusters: 60\n",
      "purity for n=600, k=3400 is 0.3558, number of >0.8 clusters: 59\n",
      "purity for n=600, k=3500 is 0.3603, number of >0.8 clusters: 46\n",
      "purity for n=600, k=3600 is 0.3635, number of >0.8 clusters: 51\n",
      "purity for n=600, k=3700 is 0.3663, number of >0.8 clusters: 63\n",
      "purity for n=600, k=3800 is 0.3722, number of >0.8 clusters: 57\n",
      "purity for n=600, k=3900 is 0.3798, number of >0.8 clusters: 60\n",
      "purity for n=600, k=4000 is 0.3775, number of >0.8 clusters: 65\n",
      "purity for n=600, k=4100 is 0.3921, number of >0.8 clusters: 58\n",
      "purity for n=600, k=4200 is 0.3851, number of >0.8 clusters: 51\n",
      "purity for n=600, k=4300 is 0.3893, number of >0.8 clusters: 63\n",
      "purity for n=600, k=4400 is 0.3944, number of >0.8 clusters: 74\n",
      "purity for n=600, k=4500 is 0.4042, number of >0.8 clusters: 64\n",
      "doing LSA with 700 components...\n",
      "\n",
      "purity for n=700, k=2500 is 0.3148, number of >0.8 clusters: 39\n",
      "purity for n=700, k=2600 is 0.3298, number of >0.8 clusters: 58\n",
      "purity for n=700, k=2700 is 0.3231, number of >0.8 clusters: 37\n",
      "purity for n=700, k=2800 is 0.3382, number of >0.8 clusters: 51\n",
      "purity for n=700, k=2900 is 0.3353, number of >0.8 clusters: 51\n",
      "purity for n=700, k=3000 is 0.3438, number of >0.8 clusters: 53\n",
      "purity for n=700, k=3100 is 0.3472, number of >0.8 clusters: 46\n",
      "purity for n=700, k=3200 is 0.3505, number of >0.8 clusters: 53\n",
      "purity for n=700, k=3300 is 0.3503, number of >0.8 clusters: 53\n",
      "purity for n=700, k=3400 is 0.3652, number of >0.8 clusters: 72\n",
      "purity for n=700, k=3500 is 0.3591, number of >0.8 clusters: 66\n",
      "purity for n=700, k=3600 is 0.3636, number of >0.8 clusters: 50\n",
      "purity for n=700, k=3700 is 0.3684, number of >0.8 clusters: 56\n",
      "purity for n=700, k=3800 is 0.3735, number of >0.8 clusters: 62\n",
      "purity for n=700, k=3900 is 0.3796, number of >0.8 clusters: 70\n",
      "purity for n=700, k=4000 is 0.3854, number of >0.8 clusters: 63\n",
      "purity for n=700, k=4100 is 0.3827, number of >0.8 clusters: 47\n",
      "purity for n=700, k=4200 is 0.3874, number of >0.8 clusters: 49\n",
      "purity for n=700, k=4300 is 0.3885, number of >0.8 clusters: 67\n",
      "purity for n=700, k=4400 is 0.4008, number of >0.8 clusters: 63\n",
      "purity for n=700, k=4500 is 0.3964, number of >0.8 clusters: 73\n"
     ]
    }
   ],
   "source": [
    "n_components = [n * 100 for n in xrange(3, 8)]\n",
    "ks = [k * 100 for k in xrange(25, 46)]\n",
    "\n",
    "km_grid_hyperparam_purity = {}\n",
    "km_grid_hyperparam_res = {}\n",
    "\n",
    "for n in n_components:\n",
    "    print 'doing LSA with %d components...' % n\n",
    "    print\n",
    "\n",
    "    U, S, Vt = randomized_svd(X, n_components=n)\n",
    "    V = Vt.T\n",
    "\n",
    "    X_red_grid = X.dot(V)\n",
    "    X_red_grid = normalizer.fit_transform(X_red_grid)\n",
    "\n",
    "\n",
    "    for k in ks:\n",
    "        if k > 1000 and n > 70:\n",
    "            km_grid = MiniBatchKMeans(n_clusters=k, init_size=k*3, n_init=10, init='random')\n",
    "        else:\n",
    "            km_grid = MiniBatchKMeans(n_clusters=k, init_size=k*3, n_init=10)\n",
    "        km_grid.fit(X_red_grid)\n",
    "\n",
    "        km_grid_hyperparam_res[(n, k)] = km_grid.labels_\n",
    "        cluster_purity = evaluate.overall_purity(km_grid.labels_)\n",
    "        km_grid_hyperparam_purity[(n, k)] = cluster_purity\n",
    "\n",
    "        no_pure_clusters = len(evaluate.high_purity_clusters(km_grid.labels_, threshold=0.8))\n",
    "\n",
    "        print 'purity for n=%d, k=%d is %0.4f, number of >0.8 clusters: %d' % (n, k, cluster_purity, no_pure_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall purity 0.3964\n",
      "number of high purity clusters of size at least 5 is 73\n",
      "\n",
      "- Astronomical catalogues (id=538) size=53, purity=0.9811\n",
      "- Stochastic processes (id=1999) size=18, purity=0.8889\n",
      "- Group theory (id=175) size=17, purity=0.8235\n",
      "- Quantum mechanics (id=1751) size=16, purity=0.9375\n",
      "- Quantum mechanics (id=1153) size=12, purity=0.9167\n",
      "- Physics (id=530) size=11, purity=0.8182\n",
      "- Probability distributions (id=3138) size=11, purity=0.8182\n",
      "- Cartographic projections (id=4020) size=11, purity=0.9091\n",
      "- Deformation (id=74) size=10, purity=0.8000\n",
      "- Astrodynamics (id=826) size=10, purity=0.8000\n",
      "- Thermodynamics (id=918) size=10, purity=0.9000\n",
      "- Electromagnetism (id=1755) size=10, purity=0.8000\n",
      "- Group theory (id=3301) size=10, purity=0.9000\n",
      "- National Basketball Association seasons (id=282) size=9, purity=1.0000\n",
      "- Electrochemistry (id=2) size=8, purity=0.8750\n",
      "- Set theory (id=3525) size=8, purity=1.0000\n",
      "- Enzymes (id=176) size=7, purity=0.8571\n",
      "- Thermodynamics (id=271) size=7, purity=0.8571\n",
      "- Differential equations (id=2099) size=7, purity=0.8571\n",
      "- Mathematical analysis (id=2784) size=7, purity=0.8571\n",
      "- Astronomical catalogues of stars (id=2982) size=7, purity=0.8571\n",
      "- Electromagnetism (id=3078) size=7, purity=0.8571\n",
      "- Special hypergeometric functions (id=3223) size=7, purity=1.0000\n",
      "- Estimation theory (id=3230) size=7, purity=0.8571\n",
      "- Measure theory (id=3819) size=7, purity=0.8571\n",
      "- Polyhedra (id=511) size=6, purity=1.0000\n",
      "- Homology theory (id=769) size=6, purity=0.8333\n",
      "- Measures (measure theory) (id=912) size=6, purity=0.8333\n",
      "- Group theory (id=930) size=6, purity=1.0000\n",
      "- Algebraic topology (id=1099) size=6, purity=1.0000\n",
      "- Control theory (id=1446) size=6, purity=0.8333\n",
      "- Mathematical logic (id=1768) size=6, purity=1.0000\n",
      "- Chemical properties (id=1809) size=6, purity=0.8333\n",
      "- Econometrics (id=1977) size=6, purity=1.0000\n",
      "- Macroeconomics and monetary economics (id=2522) size=6, purity=1.0000\n",
      "- Cardinal numbers (id=2565) size=6, purity=1.0000\n",
      "- Propositional calculus (id=2603) size=6, purity=1.0000\n",
      "- Quantum mechanics (id=2923) size=6, purity=0.8333\n",
      "- Color (id=3048) size=6, purity=0.8333\n",
      "- Constellations (id=3499) size=6, purity=0.8333\n",
      "- Mathematical finance (id=28) size=5, purity=1.0000\n",
      "- General relativity (id=121) size=5, purity=0.8000\n",
      "- Fluid dynamics (id=145) size=5, purity=0.8000\n",
      "- Statistics (id=185) size=5, purity=0.8000\n",
      "- Thermodynamics (id=238) size=5, purity=1.0000\n",
      "- Wireless (id=278) size=5, purity=1.0000\n",
      "- Mathematical logic (id=364) size=5, purity=0.8000\n",
      "- Quantum mechanics (id=541) size=5, purity=0.8000\n",
      "- Abstract algebra (id=569) size=5, purity=1.0000\n",
      "- Optimization algorithms and methods (id=703) size=5, purity=1.0000\n",
      "- Chaos theory (id=739) size=5, purity=0.8000\n",
      "- Differential equations (id=764) size=5, purity=0.8000\n",
      "- Mechanical ventilation (id=887) size=5, purity=0.8000\n",
      "- Functional analysis (id=1179) size=5, purity=0.8000\n",
      "- Fluid dynamics (id=1202) size=5, purity=0.8000\n",
      "- Number theory (id=1251) size=5, purity=0.8000\n",
      "- Graph theory (id=1255) size=5, purity=1.0000\n",
      "- Statistics (id=1312) size=5, purity=1.0000\n",
      "- Physics (id=1686) size=5, purity=1.0000\n",
      "- Concepts in physics (id=1689) size=5, purity=0.8000\n",
      "- Physics (id=1753) size=5, purity=1.0000\n",
      "- General topology (id=1898) size=5, purity=0.8000\n",
      "- Stochastic processes (id=2086) size=5, purity=1.0000\n",
      "- Quantum mechanics (id=2100) size=5, purity=0.8000\n",
      "- Numerical analysis (id=2298) size=5, purity=1.0000\n",
      "- Fluid mechanics (id=2323) size=5, purity=0.8000\n",
      "- Mathematical analysis (id=2434) size=5, purity=0.8000\n",
      "- Algebraic geometry (id=2520) size=5, purity=0.8000\n",
      "- Transistors (id=2793) size=5, purity=0.8000\n",
      "- Complex analysis (id=3060) size=5, purity=0.8000\n",
      "- Biostatistics (id=3280) size=5, purity=0.8000\n",
      "- Flight (id=3917) size=5, purity=0.8000\n",
      "- Thermodynamics (id=4367) size=5, purity=1.0000\n"
     ]
    }
   ],
   "source": [
    "evaluate.report_overall(km_grid_hyperparam_res[(700, 4500)], purity_threshold=0.8, sort_by='size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(cluster_evaluation)\n",
    "evaluate = cluster_evaluation.Evaluator(doc_titles=titles, doc_ids=ids, \n",
    "                                        doc_ids_definitions=rels, doc_categories=doc_categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall purity 0.3964\n",
      "number of high purity clusters of size at least 5 is 73\n",
      "\n",
      "category \"Mathematical finance\", cluster_id=28, size=5:\n",
      "top categories: [(u'Mathematical finance', 5), (u'Mathematical science occupations', 4), (u'Fields of finance', 4), (u'Applied mathematics', 4), (u'Fields of application of statistics', 4)]\n",
      "σ: (constant volatility: 2.71), (short rate volatility: 0.93), (model: 0.89), (security price: 0.86), (stock prices: 0.82)\n",
      "\n",
      "category \"Deformation\", cluster_id=74, size=10:\n",
      "top categories: [(u'Deformation', 8), (u'Plasticity', 8), (u'Mechanics', 8), (u'Solid mechanics', 8), (u'Continuum mechanics', 7)]\n",
      "σ: (Examples: 0.99), (Main: 0.99), (Cauchy stress: 0.95), (articles: 0.95), (shear strength: 0.93), (Spinors in three dimensions: 0.89), (normal stress: 0.89)\n",
      "\n",
      "category \"General relativity\", cluster_id=121, size=5:\n",
      "top categories: [(u'General relativity', 4), (u'Theory of relativity', 4), (u'Physical cosmology', 3), (u'Theories of gravitation', 3), (u'Astronomical objects', 2)]\n",
      "σ: (shear: 0.93)\n",
      "\n",
      "category \"Statistics\", cluster_id=185, size=5:\n",
      "top categories: [(u'Statistics', 4), (u'Statistical theory', 4), (u'Scientific theories', 3), (u'Estimation theory', 2), (u'Bayesian statistics', 2)]\n",
      "σ: (variance: 1.86), (finite variance: 0.99), (constraint: 0.96), (standard deviation: 0.92), (population variance: 0.91), (true variance: 0.90), (error variance: 0.89), (probability theory: 0.88), (estimator: 0.87), (Jeffreys: 0.83), (real value: 0.81)\n",
      "\n",
      "category \"Homology theory\", cluster_id=769, size=6:\n",
      "top categories: [(u'Homology theory', 5), (u'Algebraic topology', 5), (u'Homological algebra', 5), (u'Mathematicians by field', 1), (u'American scientists', 1)]\n",
      "σ: (basis element: 0.92), (restriction: 0.92), (faces: 0.86), (prism: 0.83)\n",
      "\n",
      "category \"Thermodynamics\", cluster_id=918, size=10:\n",
      "top categories: [(u'Thermodynamics', 9), (u'Physics', 7), (u'Physical chemistry', 6), (u'Dynamical systems', 6), (u'Engineering concepts', 5)]\n",
      "σ: (linearly related: 0.92), (creation: 0.86)\n",
      "\n",
      "category \"Quantum mechanics\", cluster_id=1153, size=12:\n",
      "top categories: [(u'Quantum mechanics', 11), (u'Theoretical physics', 11), (u'Philosophy of physics', 9), (u'Physics', 9), (u'Modern physics', 8)]\n",
      "σ: (Scattering cross-section: 0.99), (standard deviation: 0.99), (variance: 0.95), (momentum: 0.83)\n",
      "\n",
      "category \"Fluid dynamics\", cluster_id=1202, size=5:\n",
      "top categories: [(u'Fluid dynamics', 4), (u'Waves', 4), (u'Physical oceanography', 4), (u'Water waves', 4), (u'Partial differential equations', 2)]\n",
      "σ: (gravity: 0.86), (surface tension coefficient: 0.86), (surface tension: 0.86), (frequencies: 0.84)\n",
      "\n",
      "category \"Statistics\", cluster_id=1312, size=5:\n",
      "top categories: [(u'Statistics', 5), (u'Probability distributions', 3), (u'Probability theory', 3), (u'Theory of probability distributions', 2), (u'Point processes', 1)]\n",
      "σ: (standard deviation: 1.72), (median: 0.89), (central moment: 0.83)\n",
      "\n",
      "category \"Control theory\", cluster_id=1446, size=6:\n",
      "top categories: [(u'Control theory', 5), (u'Statistics', 4), (u'Statistical theory', 4), (u'Discrete mathematics', 4), (u'Management', 3)]\n",
      "σ: (scale parameter: 0.96), (Cauchy distribution: 0.87)\n",
      "\n",
      "category \"Concepts in physics\", cluster_id=1689, size=5:\n",
      "top categories: [(u'Concepts in physics', 4), (u'Periodic phenomena', 3), (u'Physical phenomena', 3), (u'Partial differential equations', 3), (u'Waves', 3)]\n",
      "σ: (spread: 0.89), (spatial spread: 0.84), (Gaussian wave packet: 0.81)\n",
      "\n",
      "category \"Quantum mechanics\", cluster_id=1751, size=16:\n",
      "top categories: [(u'Quantum mechanics', 15), (u'Theoretical physics', 12), (u'Particle physics', 10), (u'Modern physics', 9), (u'Philosophy of physics', 9)]\n",
      "σ: (magnetic moment: 0.89), (particles: 0.84)\n",
      "\n",
      "category \"Physics\", cluster_id=1753, size=5:\n",
      "top categories: [(u'Physics', 5), (u'Theoretical physics', 4), (u'Differential geometry', 3), (u'Special relativity', 3), (u'Engineering concepts', 3)]\n",
      "σ: (material: 0.95), (electrical conductivity: 0.89)\n",
      "\n",
      "category \"General topology\", cluster_id=1898, size=5:\n",
      "top categories: [(u'General topology', 4), (u'Topological spaces', 3), (u'Topology', 3), (u'Mathematical analysis', 2), (u'Functional analysis', 2)]\n",
      "σ: (intersection: 0.89)\n",
      "\n",
      "category \"Econometrics\", cluster_id=1977, size=6:\n",
      "top categories: [(u'Econometrics', 6), (u'Statistics', 5), (u'Data analysis', 5), (u'Estimation theory', 5), (u'Mathematical optimization', 5)]\n",
      "σ: (estimator: 0.95), (constant variance: 0.92), (Gauss-Markov theorem: 0.86), (covariance matrix: 0.86), (variance: 0.86), (identity matrix: 0.85), (variance matrix: 0.83)\n",
      "\n",
      "category \"Stochastic processes\", cluster_id=1999, size=18:\n",
      "top categories: [(u'Stochastic processes', 16), (u'Probability theory', 14), (u'Statistics', 13), (u'Statistical data types', 13), (u'Martingale theory', 4)]\n",
      "σ: (variance: 0.96), (assets drift: 0.95), (volatility: 0.95), (drift field: 0.87), (drift coefficient: 0.83)\n",
      "\n",
      "category \"Quantum mechanics\", cluster_id=2100, size=5:\n",
      "top categories: [(u'Quantum mechanics', 4), (u'Concepts in physics', 3), (u'Physics', 3), (u'Quantum electronics', 2), (u'Electromagnetism', 2)]\n",
      "σ: (orbit interaction couple spin matrices: 0.89), (quasi-momentum: 0.89)\n",
      "\n",
      "category \"Probability distributions\", cluster_id=3138, size=11:\n",
      "top categories: [(u'Probability distributions', 9), (u'Continuous distributions', 6), (u'Statistics', 4), (u'Exponential family distributions', 2), (u'Analytic number theory', 2)]\n",
      "σ: (variances: 1.97), (means: 1.66), (moment about the mean: 0.93), (standard deviation: 0.87), (statistic: 0.83)\n",
      "\n",
      "category \"Estimation theory\", cluster_id=3230, size=7:\n",
      "top categories: [(u'Estimation theory', 6), (u'Mathematical optimization', 6), (u'Regression analysis', 6), (u'Statistics', 4), (u'Analysis of variance', 4)]\n",
      "σ: (residual variance: 0.99)\n",
      "\n",
      "category \"Constellations\", cluster_id=3499, size=6:\n",
      "top categories: [(u'Constellations', 5), (u'Main sequence stars', 4), (u'Gliese and GJ objects', 4), (u'Constellations listed by Ptolemy', 4), (u'Astronomical catalogues of stars', 4)]\n",
      "σ: (velocity dispersion: 0.96), (recall: 0.92), (elliptical galaxies: 0.92), (stellar: 0.92)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate.find_identifier(km_grid_hyperparam_res[(700, 4500)], purity_threshold=0.8, id=u'σ', collection_weighting=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 5\n",
      "\n",
      "- Newman–Penrose formalism (categories: Theoretical physics, Mechanics, Mathematical physics, Modern physics, Mathematics, ...) n_ingo Λ_scalar Φ_22 Φ_21 Φ_20 α ε ν ρ D n_vector ϕ Φ_10 Φ_11 d ϕ_2 m_b m_a l Ψ_i_scalar ϝ_i ϵ t R_trace-fre Φ_01 Φ_00 Φ_02 β κ R_normal G S c g R_tensor ϝ_i_field ϕ_1 ϕ_0 Λ h_× γ λ σ F ϕ_j ϕ_i R_einstein R b j n l_b r Ψ_4 Ψ_2 Ψ_3 Ψ_0 Ψ_1 Ψ_i_ricci-np n_null Δ n_a n_b δ θ μ π τ r_direct Y R_relat l_a h_+ Ψ_i ϝ_i_scalar R_part Ψ_i_weyl-np r_propag m ∇_m ∇_l Ψ_4_scalar ∇_n Φ_12 ∇_a ∇_b\n",
      "- Weyl scalar (categories: General relativity, Theory of relativity, Theories of gravitation, Physical cosmology) Ψ_4 Ψ_2 Ψ_3 Ψ_0 Ψ_1 Δ Λ n_a D h_× α γ β ε δ λ κ ν μ ρ π σ τ R h_+ Ψ_i m l n Ψ_4_scalar\n",
      "- Non-expanding horizon (categories: Astrophysics, General relativity, Unsolved problems in physics, Astronomical objects, Density, ...) n_ingo Φ_20 α ε δ ρ D ω n_field F_field T Φ_10 v_ingo Λ_field d ϝ_i_field m_b m_a l Ψ_i_scalar ϝ_i D_connect h v_coordin g_genus Φ_01 Φ_00 Φ_02 Λ β V_a κ G S c g F_strength n_normal ϕ_2 ϕ_1 ϕ_0 ϕ_i_scalar Ψ_2_scalar D_deriv σ ϕ_i_maxwell-np F ϕ_j ϕ_i ϝ_i_scalar R V T_definit b F_electromagnet j n l_b v Ψ_2 Ψ_0 Ψ_1 Δ n_a L_l l_field n_b θ μ π τ l_a Ψ_i l_normal Ψ_2_weyl-np Ψ_i_weyl-np m ∇_b ∇_a\n",
      "- Ricci scalars (Newman-Penrose formalism) (categories: General relativity, Theory of relativity, Theories of gravitation, Physical cosmology) π_distribut Λ_scalar Φ_01 Φ_00 ϕ_1 ϕ_0 Δ Λ n_a n_b τ Φ_22 Φ_21 Φ_20 ϝ_i_field α γ l_a ε δ λ κ ν μ ϕ_i_scalar ρ π σ ϕ_i_maxwell-np R_normal D ϕ_j ϕ_i β π_equat R_einstein R Φ_12 Φ_10 Φ_11 π_einstein Λ_curvatur π_field b R_part g ϕ_2 m_b m_a j m l R_tensor n l_b ϝ_i_scalar ϝ_i Φ_02 π_energy-momentum R_trace-fre\n",
      "- Isolated horizon (categories: Astrophysics, General relativity, Theory of relativity, Theories of gravitation, Physical cosmology, ...) Δ_tensor Ψ_0 Ψ_1 Δ_equat Δ_rate Φ_01 Φ_00 ϕ_0 Δ D_a L_l Ω ρ_expans Φ_20 l_field α γ β ε V_a Δ_normal κ ν μ ξ ρ π σ τ l_normal S R U T Φ_10 V X σ_shear b Δ_field ϕ_2 h m l l_class n l_b Φ_02 n_region y z\n",
      "\n",
      "common terms: (ρ π σ τ m l n α R ε Δ β κ μ)\n",
      "top categories: [(u'General relativity', 4), (u'Theory of relativity', 4), (u'Physical cosmology', 3), (u'Theories of gravitation', 3), (u'Astronomical objects', 2)]\n",
      "purity: 0.800\n",
      "relations:\n",
      "    D: (derivatives: 0.96), (connection: 0.93), (horizon: 0.86)\n",
      "    D_a: (commutator: 0.83), (connection: 0.83)\n",
      "    F: (electromagnetic field strength: 0.95), (antisymmetric: 0.83)\n",
      "    R: (Einstein tensor: 1.93), (part: 1.93), (trace-free: 1.85), (normalization: 0.81), (normalization relations: 0.81)\n",
      "    S: (2-spheres ∆: 0.91), (foliation leaf ∆: 0.87)\n",
      "    T: (definition: 0.89)\n",
      "    g: (genus: 0.87)\n",
      "    h_+: (fields: 0.99), (everything: 0.83), (flat space: 0.83)\n",
      "    h_×: (everything: 0.95), (fields: 0.89), (plus: 0.87), (gravitational radiation: 0.83)\n",
      "    l: (equivalence class: 1.94), (normal field: 1.88), (tangent: 1.88), (geodesic: 0.82)\n",
      "    l_a: (horizon ∆: 0.89)\n",
      "    m: (frame: 0.81)\n",
      "    n: (ingoing: 1.68), (normal field: 0.96), (null vector: 0.89), (off-horizon regions: 0.87)\n",
      "    n_a: (first tetrad covector: 0.99)\n",
      "    r: (direction: 0.99), (propagation: 0.89)\n",
      "    v: (Eddington-Finkelstein null coordinates: 0.87), (ingoing: 0.87), (leaves: 0.87)\n",
      "    Δ: (submanifold: 0.99), (null: 0.95), (tangent: 0.95), (field equations: 0.89), (outgoing expansion rate: 0.89), (stress-energy tensor: 0.89), (equivalence class: 0.83), (normal field: 0.83)\n",
      "    Λ: (NP curvature scalar: 1.82), (electrovacuum: 1.76), (fields: 0.95), (NEHs: 0.89), (scalars: 0.83), (Vacuum: 0.81), (types: 0.81)\n",
      "    Φ_00: (condition: 0.99), (scalars: 0.99), (waves: 0.89)\n",
      "    Φ_11: (scalars: 0.89)\n",
      "    Ψ_0: (transverse component: 0.99), (longitudinal component: 0.95), (longitudinal radiation terms: 0.95), (waves: 0.89)\n",
      "    Ψ_1: (longitudinal component: 0.99), (source: 0.95), (black hole: 0.83), (transverse component: 0.83)\n",
      "    Ψ_2: (distances: 0.91), (Coulomb term: 0.86), (Ricci-NP quantities: 0.83), (Weyl-NP scalars: 0.83)\n",
      "    Ψ_3: (source: 0.83)\n",
      "    Ψ_4: (scalar: 1.86), (Weyl: 1.78), (scalars: 0.93), (appropriate frame: 0.87), (longitudinal radiation terms: 0.81), (outgoing transverse radiation terms: 0.81)\n",
      "    Ψ_i: (Weyl-NP scalars: 1.94), (Ricci-NP scalars: 0.93), (definitions: 0.93), (Weyl-NP: 0.90), (spin coefficients: 0.89), (Ricci-NP: 0.83)\n",
      "    κ: (Newman-Penrose formalism: 0.93), (geodesic: 0.93), (language: 0.81)\n",
      "    π: (Einsteins field equations: 0.96), (energy-momentum distribution: 0.81)\n",
      "    ρ: (hypersurface: 1.70), (expansion: 0.93), (twist: 0.93), (geodesic: 0.87)\n",
      "    σ: (shear: 0.93)\n",
      "    ϕ_i: (Maxwell-NP scalars: 0.99), (complex Maxwell-NP scalars: 0.81)\n",
      "    ϝ_i: (scalars: 2.60), (fields: 2.49)\n"
     ]
    }
   ],
   "source": [
    "evaluate.print_cluster(km_grid_hyperparam_res[(700, 4500)], 121, collection_weighting=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall purity 0.3964\n",
      "number of high purity clusters of size at least 5 is 73\n",
      "\n",
      "category \"Deformation\", cluster_id=74, size=10:\n",
      "top categories: [(u'Deformation', 8), (u'Plasticity', 8), (u'Mechanics', 8), (u'Solid mechanics', 8), (u'Continuum mechanics', 7)]\n",
      "ϕ: (slope: 8.13), (angle: 6.15)\n",
      "\n",
      "category \"Statistics\", cluster_id=185, size=5:\n",
      "top categories: [(u'Statistics', 4), (u'Statistical theory', 4), (u'Scientific theories', 3), (u'Estimation theory', 2), (u'Bayesian statistics', 2)]\n",
      "ϕ: (Jeffreys: 8.35)\n",
      "\n",
      "category \"Physics\", cluster_id=530, size=11:\n",
      "top categories: [(u'Physics', 9), (u'Theory of relativity', 8), (u'Special relativity', 7), (u'Concepts in physics', 6), (u'Concepts by field', 4)]\n",
      "ϕ: (rapidity: 14.94), (hyperbolic angle: 8.70), (hyperbolic rotation: 7.51)\n",
      "\n",
      "category \"Differential equations\", cluster_id=764, size=5:\n",
      "top categories: [(u'Differential equations', 4), (u'Partial differential equations', 3), (u'Mathematical analysis', 2), (u'Fluid mechanics', 2), (u'Theoretical physics', 2)]\n",
      "ϕ: (vector functions: 8.99), (compact support: 8.64), (continuously differentiable: 8.64)\n",
      "\n",
      "category \"Astrodynamics\", cluster_id=826, size=10:\n",
      "top categories: [(u'Astrodynamics', 8), (u'Orbits', 7), (u'Celestial mechanics', 7), (u'Gravitation', 6), (u'Periodic phenomena', 6)]\n",
      "ϕ: (flight path angle: 8.99), (assumptions: 8.13)\n",
      "\n",
      "category \"Concepts in physics\", cluster_id=1689, size=5:\n",
      "top categories: [(u'Concepts in physics', 4), (u'Periodic phenomena', 3), (u'Physical phenomena', 3), (u'Partial differential equations', 3), (u'Waves', 3)]\n",
      "ϕ: (phase angle: 13.93), (wavenumber: 8.86), (Taylor series: 8.35), (phase: 6.49)\n",
      "\n",
      "category \"Quantum mechanics\", cluster_id=1751, size=16:\n",
      "top categories: [(u'Quantum mechanics', 15), (u'Theoretical physics', 12), (u'Particle physics', 10), (u'Modern physics', 9), (u'Philosophy of physics', 9)]\n",
      "ϕ: (form: 13.99), (classical state vectors: 9.21), (Schrödinger: 8.86), (three-vector potential: 8.86), (classical description: 8.35), (phase difference: 8.28), (charge operator: 8.13), (magnetic flux operator: 8.13), (same time-periodicity: 8.13), (superconductors: 7.80), (analog: 7.74), (scalar potential: 7.73), (Josephson: 7.42)\n",
      "\n",
      "category \"Physics\", cluster_id=1753, size=5:\n",
      "top categories: [(u'Physics', 5), (u'Theoretical physics', 4), (u'Differential geometry', 3), (u'Special relativity', 3), (u'Engineering concepts', 3)]\n",
      "ϕ: (energy tensor: 7.74), (Klein: 7.51), (scalar field: 6.68)\n",
      "\n",
      "category \"Mathematical logic\", cluster_id=1768, size=6:\n",
      "top categories: [(u'Mathematical logic', 6), (u'Modal logic', 3), (u'Non-classical logic', 3), (u'Logic', 3), (u'Theoretical computer science', 3)]\n",
      "ϕ: (path formulae: 16.48), (standing: 8.88), (fórmulas: 8.66), (abbreviation: 8.64), (bound variable: 8.64), (interpretations: 8.31), (minimization: 8.13), (symbol: 7.93), (fact: 7.80), (path: 7.46)\n",
      "\n",
      "category \"Quantum mechanics\", cluster_id=2100, size=5:\n",
      "top categories: [(u'Quantum mechanics', 4), (u'Concepts in physics', 3), (u'Physics', 3), (u'Quantum electronics', 2), (u'Electromagnetism', 2)]\n",
      "ϕ: (angle: 6.38)\n",
      "\n",
      "category \"Fluid mechanics\", cluster_id=2323, size=5:\n",
      "top categories: [(u'Fluid mechanics', 4), (u'Fluid dynamics', 3), (u'Physical oceanography', 3), (u'Applied and interdisciplinary physics', 2), (u'Gases', 2)]\n",
      "ϕ: (latitude: 5.99)\n",
      "\n",
      "category \"Cardinal numbers\", cluster_id=2565, size=6:\n",
      "top categories: [(u'Cardinal numbers', 6), (u'Infinity', 6), (u'Set theory', 5), (u'Ordinal numbers', 5), (u'Numbers', 5)]\n",
      "ϕ: (proposition: 9.21)\n",
      "\n",
      "category \"Electromagnetism\", cluster_id=3078, size=7:\n",
      "top categories: [(u'Electromagnetism', 6), (u'Physics', 5), (u'Electrostatics', 3), (u'Special relativity', 3), (u'Force', 3)]\n",
      "ϕ: (validity: 8.57), (Laplaces equation: 7.29), (scalar function: 7.27)\n",
      "\n",
      "category \"Measure theory\", cluster_id=3819, size=7:\n",
      "top categories: [(u'Measure theory', 6), (u'Mathematical analysis', 5), (u'Theorems in analysis', 3), (u'Probability theory', 3), (u'Probability distributions', 2)]\n",
      "ϕ: (M. Riesz extension theorem: 8.35)\n",
      "\n",
      "category \"Flight\", cluster_id=3917, size=5:\n",
      "top categories: [(u'Flight', 4), (u'Applied and interdisciplinary physics', 3), (u'Firearms', 3), (u'Ammunition', 3), (u'Mechanics', 3)]\n",
      "ϕ: (elevation: 9.06), (angle: 5.68)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate.find_identifier(km_grid_hyperparam_res[(700, 4500)], purity_threshold=0.8, id=u'ϕ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores below are without df-weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing LSA with 200 components...\n",
      "\n",
      "purity for n=200, k=2000 is 0.2913, number of >0.8 clusters: 21\n",
      "purity for n=200, k=2100 is 0.3085, number of >0.8 clusters: 44\n",
      "purity for n=200, k=2200 is 0.3157, number of >0.8 clusters: 37\n",
      "purity for n=200, k=2300 is 0.3182, number of >0.8 clusters: 40\n",
      "purity for n=200, k=2400 is 0.3141, number of >0.8 clusters: 36\n",
      "purity for n=200, k=2500 is 0.3291, number of >0.8 clusters: 45\n",
      "purity for n=200, k=2600 is 0.3321, number of >0.8 clusters: 39\n",
      "purity for n=200, k=2700 is 0.3269, number of >0.8 clusters: 36\n",
      "purity for n=200, k=2800 is 0.3315, number of >0.8 clusters: 39\n",
      "purity for n=200, k=2900 is 0.3433, number of >0.8 clusters: 38\n",
      "purity for n=200, k=3000 is 0.3509, number of >0.8 clusters: 56\n",
      "purity for n=200, k=3100 is 0.3592, number of >0.8 clusters: 49\n",
      "purity for n=200, k=3200 is 0.3511, number of >0.8 clusters: 35\n",
      "purity for n=200, k=3300 is 0.3499, number of >0.8 clusters: 46\n",
      "purity for n=200, k=3400 is 0.3679, number of >0.8 clusters: 54\n",
      "purity for n=200, k=3500 is 0.3640, number of >0.8 clusters: 54\n",
      "purity for n=200, k=3600 is 0.3777, number of >0.8 clusters: 53\n",
      "purity for n=200, k=3700 is 0.3750, number of >0.8 clusters: 57\n",
      "purity for n=200, k=3800 is 0.3735, number of >0.8 clusters: 53\n",
      "purity for n=200, k=3900 is 0.3877, number of >0.8 clusters: 67\n",
      "purity for n=200, k=4000 is 0.3838, number of >0.8 clusters: 61\n",
      "doing LSA with 300 components...\n",
      "\n",
      "purity for n=300, k=2000 is 0.2936, number of >0.8 clusters: 33\n",
      "purity for n=300, k=2100 is 0.3125, number of >0.8 clusters: 44\n",
      "purity for n=300, k=2200 is 0.3021, number of >0.8 clusters: 30\n",
      "purity for n=300, k=2300 is 0.3203, number of >0.8 clusters: 41\n",
      "purity for n=300, k=2400 is 0.3150, number of >0.8 clusters: 42\n",
      "purity for n=300, k=2500 is 0.3186, number of >0.8 clusters: 35\n",
      "purity for n=300, k=2600 is 0.3222, number of >0.8 clusters: 36\n",
      "purity for n=300, k=2700 is 0.3318, number of >0.8 clusters: 43\n",
      "purity for n=300, k=2800 is 0.3458, number of >0.8 clusters: 64\n",
      "purity for n=300, k=2900 is 0.3472, number of >0.8 clusters: 52\n",
      "purity for n=300, k=3000 is 0.3416, number of >0.8 clusters: 48\n",
      "purity for n=300, k=3100 is 0.3605, number of >0.8 clusters: 59\n",
      "purity for n=300, k=3200 is 0.3496, number of >0.8 clusters: 62\n",
      "purity for n=300, k=3300 is 0.3643, number of >0.8 clusters: 51\n",
      "purity for n=300, k=3400 is 0.3689, number of >0.8 clusters: 54\n",
      "purity for n=300, k=3500 is 0.3620, number of >0.8 clusters: 59\n",
      "purity for n=300, k=3600 is 0.3662, number of >0.8 clusters: 60\n",
      "purity for n=300, k=3700 is 0.3729, number of >0.8 clusters: 55\n",
      "purity for n=300, k=3800 is 0.3836, number of >0.8 clusters: 68\n",
      "purity for n=300, k=3900 is 0.3877, number of >0.8 clusters: 52\n",
      "purity for n=300, k=4000 is 0.3921, number of >0.8 clusters: 67\n",
      "doing LSA with 400 components...\n",
      "\n",
      "purity for n=400, k=2000 is 0.3066, number of >0.8 clusters: 46\n",
      "purity for n=400, k=2100 is 0.3033, number of >0.8 clusters: 25\n",
      "purity for n=400, k=2200 is 0.3089, number of >0.8 clusters: 34\n",
      "purity for n=400, k=2300 is 0.3210, number of >0.8 clusters: 41\n",
      "purity for n=400, k=2400 is 0.3190, number of >0.8 clusters: 38\n",
      "purity for n=400, k=2500 is 0.3309, number of >0.8 clusters: 53\n",
      "purity for n=400, k=2600 is 0.3243, number of >0.8 clusters: 48\n",
      "purity for n=400, k=2700 is 0.3395, number of >0.8 clusters: 54\n",
      "purity for n=400, k=2800 is 0.3360, number of >0.8 clusters: 37\n",
      "purity for n=400, k=2900 is 0.3512, number of >0.8 clusters: 59\n",
      "purity for n=400, k=3000 is 0.3437, number of >0.8 clusters: 41\n",
      "purity for n=400, k=3100 is 0.3511, number of >0.8 clusters: 49\n",
      "purity for n=400, k=3200 is 0.3525, number of >0.8 clusters: 55\n",
      "purity for n=400, k=3300 is 0.3661, number of >0.8 clusters: 52\n",
      "purity for n=400, k=3400 is 0.3679, number of >0.8 clusters: 61\n",
      "purity for n=400, k=3500 is 0.3746, number of >0.8 clusters: 56\n",
      "purity for n=400, k=3600 is 0.3682, number of >0.8 clusters: 55\n",
      "purity for n=400, k=3700 is 0.3749, number of >0.8 clusters: 66\n",
      "purity for n=400, k=3800 is 0.3743, number of >0.8 clusters: 68\n",
      "purity for n=400, k=3900 is 0.3838, number of >0.8 clusters: 58\n",
      "purity for n=400, k=4000 is 0.3826, number of >0.8 clusters: 57\n",
      "doing LSA with 500 components...\n",
      "\n",
      "purity for n=500, k=2000 is 0.2990, number of >0.8 clusters: 39\n",
      "purity for n=500, k=2100 is 0.3123, number of >0.8 clusters: 37\n",
      "purity for n=500, k=2200 is 0.3193, number of >0.8 clusters: 58\n",
      "purity for n=500, k=2300 is 0.3244, number of >0.8 clusters: 45\n",
      "purity for n=500, k=2400 is 0.3272, number of >0.8 clusters: 49\n",
      "purity for n=500, k=2500 is 0.3204, number of >0.8 clusters: 39\n",
      "purity for n=500, k=2600 is 0.3371, number of >0.8 clusters: 39\n",
      "purity for n=500, k=2700 is 0.3430, number of >0.8 clusters: 47\n",
      "purity for n=500, k=2800 is 0.3367, number of >0.8 clusters: 49\n",
      "purity for n=500, k=2900 is 0.3387, number of >0.8 clusters: 48\n",
      "purity for n=500, k=3000 is 0.3427, number of >0.8 clusters: 48\n",
      "purity for n=500, k=3100 is 0.3471, number of >0.8 clusters: 49\n",
      "purity for n=500, k=3200 is 0.3519, number of >0.8 clusters: 60\n",
      "purity for n=500, k=3300 is 0.3718, number of >0.8 clusters: 62\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-48b8b171ddbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mkm_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mkm_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_red_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mkm_grid_hyperparam_res\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\anaconda\\2.0.1\\lib\\site-packages\\sklearn\\cluster\\k_means_.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minertia_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_labels_inertia_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\anaconda\\2.0.1\\lib\\site-packages\\sklearn\\cluster\\k_means_.pyc\u001b[0m in \u001b[0;36m_labels_inertia_minibatch\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m         results = [_labels_inertia(X[s], x_squared_norms[s],\n\u001b[1;32m-> 1357\u001b[1;33m                                    self.cluster_centers_) for s in slices]\n\u001b[0m\u001b[0;32m   1358\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minertia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minertia\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\anaconda\\2.0.1\\lib\\site-packages\\sklearn\\cluster\\k_means_.pyc\u001b[0m in \u001b[0;36m_labels_inertia\u001b[1;34m(X, x_squared_norms, centers, precompute_distances, distances)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprecompute_distances\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             return _labels_inertia_precompute_dense(X, x_squared_norms,\n\u001b[1;32m--> 542\u001b[1;33m                                                     centers, distances)\n\u001b[0m\u001b[0;32m    543\u001b[0m         inertia = _k_means._assign_labels_array(\n\u001b[0;32m    544\u001b[0m             X, x_squared_norms, centers, labels, distances=distances)\n",
      "\u001b[1;32mC:\\soft\\anaconda\\2.0.1\\lib\\site-packages\\sklearn\\cluster\\k_means_.pyc\u001b[0m in \u001b[0;36m_labels_inertia_precompute_dense\u001b[1;34m(X, x_squared_norms, centers, distances)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcenters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m     all_distances = euclidean_distances(centers, X, x_squared_norms,\n\u001b[1;32m--> 479\u001b[1;33m                                         squared=True)\n\u001b[0m\u001b[0;32m    480\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\anaconda\\2.0.1\\lib\\site-packages\\sklearn\\metrics\\pairwise.pyc\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mXX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m     \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\anaconda\\2.0.1\\lib\\site-packages\\sklearn\\utils\\extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_components = [200, 300, 400, 500]\n",
    "ks = [k * 100 for k in xrange(20, 41)]\n",
    "\n",
    "km_grid_hyperparam_purity = {}\n",
    "km_grid_hyperparam_res = {}\n",
    "\n",
    "for n in n_components:\n",
    "    print 'doing LSA with %d components...' % n\n",
    "    print\n",
    "\n",
    "    U, S, Vt = randomized_svd(X, n_components=n)\n",
    "    V = Vt.T\n",
    "\n",
    "    X_red_grid = X.dot(V)\n",
    "    X_red_grid = normalizer.fit_transform(X_red_grid)\n",
    "\n",
    "\n",
    "    for k in ks:\n",
    "        if k > 1000 and n > 70:\n",
    "            km_grid = MiniBatchKMeans(n_clusters=k, init_size=k*3, n_init=10, init='random')\n",
    "        else:\n",
    "            km_grid = MiniBatchKMeans(n_clusters=k, init_size=k*3, n_init=10)\n",
    "        km_grid.fit(X_red_grid)\n",
    "\n",
    "        km_grid_hyperparam_res[(n, k)] = km_grid.labels_\n",
    "        cluster_purity = evaluate.overall_purity(km_grid.labels_)\n",
    "        km_grid_hyperparam_purity[(n, k)] = cluster_purity\n",
    "\n",
    "        no_pure_clusters = len(evaluate.high_purity_clusters(km_grid.labels_, threshold=0.8))\n",
    "\n",
    "        print 'purity for n=%d, k=%d is %0.4f, number of >0.8 clusters: %d' % (n, k, cluster_purity, no_pure_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cosine + dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
